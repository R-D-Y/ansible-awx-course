Présentation de l'équipe et du sujet
AWX Ansible : Plongée au cœur de l'automatisation et du monde DevOps

Qui sommes-nous ?

Rémi : passionné d'informatique en systèmes, réseaux et cloud , je suis Rémi, un de vos instructeur (Avec Antoine) pour ce cours. Né et ayant grandi à Lyon, j'ai suivi un parcours académique orienté Système et réseau. Ayant obtenu mon BTS en SIO, je me suis naturellement dirigé vers un Bachelor 3 en "Système réseau cloud computing" à Sciences U. Mon parcours professionnel m'a amené à travailler chez Bourg-habitat en tant qu'administrateur système et réseau, où j'ai pu plonger dans l'administration Windows, le support de niveau 1 et 2 ainsi que la mise en place de petit projet informatique au sein de mon SI.

Actuellement, je finalise mon Master 2 en "Système réseau cloud computing" à Sciences U tout en étant en alternance à la Métropole de Lyon. En tant que pilote de projet et ressource technique au service opération. C'est ici, que j'ai eu l'opportunité de me familiariser davantage avec Linux, découvrir univers du DevOps, l'automatisation, le scripting et me plonger dans Ansible et la conteneurisation. C'est cette expérience et cette passion pour ce domaine qui nous on poussé, Antoine et moi-même, à vous proposer ce cours, afin de vous partager notre passion, ainsi que nos connaissances sur le sujet !

Antoine : Baignant dans l'informatique depuis mon jeune âge, je m'appelle Antoine votre deuxième instructeur principal pour ce cours sur Ansible AWX. Depuis ses quatre dernières années, j'ai effectué mes études en alternance dans le secteur de l'informatique. Suite à un baccalauréat professionnel système numérique, j'ai commencé mes études supérieur dans l'école Maestris pour acquérir mon BTS en tant que administrateur système dans l'entreprise SRA Informatique. Pendant ses deux années j'ai énormément appris sur l'administration système autour du logiciel SageX3 sur Windows et Linux. J'ai ensuite acquis mon Bachelor Système réseau & Cloud Computing à L'ESGI en tant que administrateur système et réseau au sein de l'entreprise Eductive Paris en poursuivant mes connaissances sur l'administration réseau & system en général et mon initialisation au Cloud.

Actuellement en Master 2 dans la filière Système réseau & Cloud Computing à l'ESGI, j'ai effectué ma première année dans une startup ou j'ai piloté un projet data qui consistait à fluidifié les données au sein de l'entreprise, quelle soit financière, cliente ou interne. C'est cette année la ou j'ai pris conscience de l'importance de l'automatisation ainsi que l'infrastructure as code dans une entreprise. C'est pour cela que aujourd'hui je me suis orienté dans l'entreprise Sanofi dans l'équipe DevOps ou je travail principalement sur la plateforme Ansible Automation Platform (AAP) afin de renforcer mes connaissances sur l'automatisation et l'infrastructure as code.

Sachez que nous sommes ravis de vous accompagner dans cette apprentissage et de partager avec vous nos connaissances, astuces et meilleures pratiques. Nous veillerons à ce que vous sortiez de cette formation avec des compétences solides et une large compréhension des sujets que nous aurons le plaisir d'aborder.

Pourquoi ce cours est indispensable pour vous ?

Vous aspirez à maîtriser le monde du DevOps, ou au moins à le découvrir ? la conteneurisation et l'automatisation vous intéresse ? Vous êtes au bon endroit ! Notre cours sur AWX Ansible est conçue pour vous transformer en une ressource technique ayant des connaissances et des compétences sur ce sujet !!!

Ce que vous allez découvrir :

Un voyage guidé : Partez de zéro et construisez un environnement pour pratiquer sur des cas concret tout au long de notre cours.
La conteneurisation : Découvrez comment et pourquoi les conteneurs ont changés la donne dans l'informatique ces 10 dernières années.
Ansible & GitHub : Découvrez 2 des outils les plus influents du moment qui gravitent autour du monde DevOps.
AWX, votre meilleur allié : Découvrez, déployez et maîtrisez ce superbe outil Open-Source conçu l'automatisation à une échelle industrielle. (Croyez-moi c'est très pratique en entreprise )
Pratique : Vous aurez l'occasion testez vos compétences et consolidez votre apprentissage tout au long du cours, avec des exercices pratiques concret, des QCM à chaque fin de chapitre pour valider vos acquis, ainsi qu'un TP final afin d'utiliser toutes les choses que vous aurez appris dans ce cours !
Explorez au-delà : Je ne vous en parle pas... ce serait un Spoil !
Les avantages de notre formation :

Interactivité : Grâce à des QCM, exercices pratiques, et un TP final votre apprentissage sera vivant et engageant, en testant pas à pas vos acquis.
Complétude : Avec un récapitulatif final du cours, nous nous assurons que vous avez bien enregistrer dans votre base de donnée interne, chaque concept important de ce cours.
Expertise : Les modules sont conçus par des ~~professionnels~~ passionnés aguerris, garantissant un contenu de qualité !!
Rejoignez-nous !

N'attendez plus ! Choisissez notre cours et placez-vous à la pointe de l'univers DevOps Avec ce cours AWX Ansible, vous êtes prêt à affronter les défis du monde professionnelle ! (Et qui sait... vous pourrez peut-être négocier votre salaire grâce à ces compétences ). Mes chères apprenant(e)s, à la fin de se cours, vous serez concrètement capable: -d'utiliser Git en entreprise -d'utiliser Ansible en entreprise (création de playbook, et plus encore). -aurez acquis des connaissances en conteneurisation -Aurez une parfaite autonomie sur la plateforme AWX

Cliquer le lien

Lire la vidéo
pour ouvrir la ressource.
La durée totale du contenu, des exercices aux vidéos explicatives, est estimée entre 10 et 12 heures.

Sommaire du cours
Présentation des Modules de Formation
Bienvenue à notre parcours de formation structuré en plusieurs modules, conçus pour vous fournir une compréhension approfondie et des compétences pratiques sur la plateforme AWX, en passant par différent points tel que la conteneurisation, l'utilisation d'Ansible, GitHub, et bien plus encore afin de réellement pouvoir monter en compétence. Voici une présentation détaillée de ce que chaque module implique :

Module 1 : Mise en place de l’environnement Ce module initial jette les bases en vous introduisant à l'environnement de travail que nous utiliserons pour pratiquer. Vous mettrez sur pied cette infrastructure à l'aide des vidéos et des textes explicatifs. nous proposerons également des tutoriels concret sur des aspects spécifique de la mise en place de l'environnement, suivis d'une vérification pratique à l'aide d'une checklist afin de savoir si l'environnement est fonctionnel. Un récapitulatif du chapitre consolidera les connaissances acquises.

Module 2 : Introduction à la Conteneurisation et YAML Ici, nous plongeons dans le monde de la conteneurisation, explorant ses concepts de base, comment créer, exécuter et gérer des conteneurs avec Docker. Nous introduirons également YAML, un langage crucial pour la configuration dans le contexte de la conteneurisation et évidemment d'Ansible. Des exercices pratiques et des évaluations consolideront votre compréhension de ces 2 thématiques...

Module 3 : Introduction à Ansible et Github Ce module vous initie à Ansible et GitHub, deux outils essentiels dans le monde DevOps et dans le cadre de votre cours. Des vidéos et des leçons fourniront les bases, tandis que des exercices pratiques vous permettront de vous familiariser avec les commandes Ansible, la création de playbooks en YAML, ainsi que de l'utilisation de GitHub.

Module 4 : Déploiement d'AWX Nous vous guiderons à travers l'utilisation d'un docker compose fournissant la plateforme AWX prête à l'emploi, suivi d'un déploiement pratique. Les guides vidéo et texte seront vos compagnons tout au long de ce module. Cela vous permettra d'être pleinement apte a faire les prochains exercices...

Module 5 : Introduction d'AWX Dans ce module, nous introduirons AWX, un outil puissant et Open-source qui est utilisé pour l'automatisation. Une série de vidéos explicatives et de textes vous aideront à comprendre les fonctionnalités clés d'AWX. Après ce module, vous connaîtrez le produit sur le bout des doigts !

Module 6 : Configuration et Pratique d’AWX Nous aborderons ici la configuration d'AWX afin de pouvoir s'en servir, nous vous guiderons à travers des exercices pratiques pour renforcer votre compréhension et vos compétences sur ce logiciel ! nous nous concentrerons sur les pipelines et les workflows, des aspects cruciaux dans le déploiement continu et l'intégration continue (CI/CD).

Module 8 : Exercice/TP FINAL C'est le moment de mettre en pratique tout ce que vous avez appris dans un projet final où vous créerez un rôle Ansible et administrerez cela via la plateforme AWX !

Module 9 : Pour aller plus loin Nous explorerons ici les concepts de CI/CD (Intégration Continue / Déploiement Continu) de façon plus poussé et introduirons d'autres plateformes professionnelles se rapprochant d'AWX.

Module 10 : Récap de tous le cours Nous terminerons notre parcours avec un récapitulatif complet de tous les modules, consolidant ainsi les connaissances et compétences acquises tout au long du cours.

À travers chaque module, des sessions QCM et des corrections détaillées seront fournies pour évaluer et renforcer votre compréhension. Cette formation est conçue pour être interactive, informative et engageante, assurant ainsi que vous repartirez avec des compétences pratiques précieuses et une compréhension approfondie des sujets abordés.

Les labs seront effectués en virtuel sous VirtualBox. La plateforme des labs est présentée ci-dessus, elle est constituée de 3 machines virtuelles reliés entre elles via un réseaux NAT Network qui sera créer par la suite. Voici le détail des machines utilisées :

| VM_MASTER | 10.0.2.15/24 |
|-----------|--------------|
| Nom DNS   | vm_master    |
| User      | vm_master    |
| Password  | toor         |

| VM_NODE   | 10.0.2.4/24  |
|-----------|--------------|
| Nom DNS   | vm_node      |
| User      | vm_node      |
| Password  | toor         |

| ADDS      | 10.0.2.50/24 |
|-----------|--------------|
| Nom DNS   |              |
| User      | Administrateur |
| Password  | Jsa100pc@    |
NOTE : Le réseau VirtualBox « ANSIBLE_AWX » doit être créé et configuré avant de démarrer les machines virtuelles. Les réseaux « Internal_Networks » sont déployés par import de l’OVA.

Prérequis :
L’infrastructure virtuelle complète décrite ci-dessus nécessite un espace disque minimum de 30 Go ainsi qu’une mémoire ram de 8 Go : ADDS Windows : 20 Go de stockage, 4 Go de ram VM_NODE Ubuntu_serveur : 5 Go de stockage, 2 Go de ram VM_MASTER Ubuntu_serveur : 5 Go de stockage, 2 Go de ram

Installation et préparation de la plateforme virtuelle
Installez Virtualbox (version 5.2 minimum pour le bien du projet et du tutoriel). Lien vers VirtualBox

Une fois virtualBox Installer, commencer par créer l’interface « ANSIBLE_AWX » via Paramètres, Réseau, ongle Réseau NAT. configurez la avec le réseau WAN 10.0.2.0/24 comme joint

Image

Notre réseau est maintenant créé, nous allons pouvoir mettre en place nos machines virtuelles.

Mise en place des machines
Commencer par cliquer sur « Fichier » puis « Importer un appareil virtuel ». Sélectionné votre machine puis cliquer sur « Ouvrir ».

Image

Contrôler ensuite les paramètres de la machine, puis sélectionner où vous souhaiter stocker vos machines. IL EST IMPORTANT DE SELECTIONNER LA POLITIQUE « Inclure toutes les adresses mac de l’interface réseau ». Puis enfin, cliquer sur « Importer », faites les mêmes actions pour les 2 machines suivantes.

Image

Vous devez maintenant avoir 3 machines disponible sur VirtualBox comme joint :

Image

Paramétrage des machines
Pour un fonctionnement correct de l’environnement de la machine Windows, dans le menu Configuration ⇒ Système ⇒ Carte mère, cochez la case « Activer les IO-APIC », si elle ne l’est pas.

Image

Vérifiez ou configurez les interfaces réseau des VM selon le schéma en première page, en Ayant sur chaque adaptateur réseaux « 1 » des 3 machines, notre réseau « ANSIBLE_AWX » créer précédemment.

Image

Clique-droit sur la machine, Configuration, puis renseigner les mêmes éléments que ci-joint.

Faites cela pour les 3 machines virtuels.

Sur la VM_MASTER uniquement, ajouté en Interface 2 et 3 des accès

par pont: Image

Vérification
Démarrer ensuite les 3 machines virtuels, nous allons effectuer les premiers test réseau afin de s’assurer que tout fonctionne correctement, et que les machines peuvent se ping entres-elles. Dans un premier temps, connecter vous aux 2 machines virtuels Ubuntu serveur et faites un IP A Afin d’afficher l’adresse IP de la machine.

Image

Effectuer ensuite des tests de ping : Depuis VM_MASTER vers VM_NODE, ADDS
Puis depuis ADDS vers VM_MASTER, VM_NODE

Image Image

Depuis VM_NODE vers VM_MASTER, ADDS :

Image

Maintenant, afin de tester le module python, rendez-vous dans votre dossier ansible et lancer le module de ping afin de vérifier le lien entre le Master et le node:

Commande : ansible all -i "10.0.2.4," -m ping -u vm_node

Image

Une fois cela fait, nous allons supprimer des routes existantes par défaut, et en rajoute une fonctionnant afin que nos container puisse sortir sur le web (cela va permettre de placer des choses sur notre github, et nos containeur pourrons y accéder.

sudo ip route del default via 192.168.1.1
sudo ip route del default via 172.20.10.1
sudo ip route add default via 10.0.2.2 dev enp0s3
Enfin cela nous servira pour la suite, nous allons effectuer quelques paramétrage notamment sur notre ADDS. Cela nous permettra par la suite d'ajouter notre hôte sur AWX afin d'y faire effectuer des actions par AWX. Nous allons ici changer notre politique d'éxécution, et action WinRM (qui sert de liaison pour AWX), nous allons ensuite ouvrir les port 5985 et 5986 qui sont les ports pour WinRM

Ouvrez un powershell en administrateur:

Set-ExecutionPolicy RemoteSigned -Force
winrm quickconfig
New-NetFirewallRule -DisplayName "WinRM HTTP" -Direction Inbound -LocalPort 5985 -Protocol TCP -Action Allow
New-NetFirewallRule -DisplayName "WinRM HTTPS" -Direction Inbound -LocalPort 5986 -Protocol TCP -Action Allow
Une fois cela fait nous allons télécharger et exécuter un script permettant le bon fonctionnement d'Ansible sur la machine Windows, puis activer l'Unencrypt étant en environnement de test et pour finir nous aurons un récapitulatif d'écoute du protocole WinRM sur la machine. *Ouvrez un powershell en administrateur: *

[Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12
$url = "https://github.com/AlbanAndrieu/ansible-windows/blob/master/files/ConfigureRemotingForAnsible.ps1"
$file = "$env:temp\ConfigureRemotingForAnsible.ps1"
Invoke-WebRequest -Uri $url -OutFile $file
powershell.exe -ExecutionPolicy ByPass -File $file
winrm enumerate winrm/config/listener
winrm get winrm/config
winrm set winrm/config/service @{AllowUnencrypted="true"}
winrm set winrm/config/service @{EnableCompatibilityHttpListener="true"}
Restart-Service WinRM
Et voilà vous votre environnement est prêt à l'emploi

Une fois que cela est fonctionnel, et pour le bien des prochains TP, il est nécessaire de faire un instantanée de chaque machine via VirtualBox, clique-droit sur la machine puis « Instantanés ». (Veillez à éteindre la machine avant d’effectuer cette action).

Explication de l'environnement de travail
Hello tout le monde !

Vous avez, dans le chapitre précédent, mis en place un environnement de travail... vous devez vous posez plein de question ! pourquoi 3 machines ? que signifie leurs noms, et enfin qu'allons nous en faire ??

Explication du réseau :

Dans notre infrastructure, nous disposons de deux types de réseaux virtuels. Le premier est le réseau NAT, qui est appliqué à l'ensemble des machines virtuelles (VM). Son rôle principal est de permettre la communication entre ces VM, tout en autorisant leur accès à internet pour l'obtention de certains paquets logiciels et l'accès au repository sur GitHub. Cependant, les VM du réseau NAT mise appart la master n'ont pas accès à la machine hôte.

Le deuxième réseau est le réseau en mode pont, qui est exclusivement associé à la machine virtuelle Master, où Ansible AWX sera installé. Ce mode de configuration permet de visualiser l'interface web d'AWX via un navigateur depuis la machine locale.

Donc pour prendre, voici à quoi ressemble le schéma:

Image

Les labs seront effectués en virtuel sous VirtualBox. La plateforme des labs est présentée ci-dessus, elle est constituée de 3 machines virtuelles reliés entre elles via un réseaux NAT Network qui sera créer par la suite.

Voici le détail des machines :

| VM_MASTER | 10.0.2.15/24 |
|-----------|--------------|
| Nom DNS   | vm_master    |
| User      | vm_master    |
| Password  | toor         |
Notre VM_MASTER est le cœur du projet, c'est d'ici que partirons toutes les informations, les TP, et les exercies. C'est ici que sera héberger la plateforme AWX, cette machine agit comme un worker, et va permettre d'être la clé de voute de notre labs. Depuis cette machines, vous créerez vos playbook, vous pratiquerez de la CI/CD github, et bien plus encore ! Le but sera donc, de ne jamais avoir a aller sur une autre machine, tout sera effectuer à partir d'ici sourire.

| VM_NODE   | 10.0.2.4/24  |
|-----------|--------------|
| Nom DNS   | vm_node      |
| User      | vm_node      |
| Password  | toor         |
La VM_NODE prendra le rôle de client dans nos exercices, comme si il s'agissait d'un poste utilisateur en entreprise, le but étant, que depuis la machine VM_MASTER, nous agirons sur la machine VM_NODE. Nous nous rendrons sur cette machine uniquement pour constaté notre travail, vous aurez tout au long du cours, des exercices a faire, dont le but sera d'interagir avec cette machine en utilisant AWX. à chaque fin de TP, nous pourrons vous demander d'aller vérifié que vos actions se sont bien déroulé. à titre d'exemple, nous pourrons vous demander, via la VM_MASTER, de lancer un playbook sur la VM_NODE afin de créer un utilisateur, à la fin de ce tp fictif, vous aurez peut-être besoin d'aller sur la vm_node afin de vérifier que l'utilisateur a bien été créer.

| ADDS      | 10.0.2.50/24 |
|-----------|--------------|
| Nom DNS   |              |
| User      | Administrateur |
| Password  | Jsa100pc@    |
l'ADDS... Celui-ci nous servira pour le TP final, mais nous n'en parlerons pas plus ici afin de vous garder la surprise... Nous avons quand-même décider de mettre une machine en Windows pour vous vanter les mérites d'AWX Ansible, car en effet, celui-ci peut effectuer des actions aussi bien sur Linux que sur WIndows !! Et pour plus d'information, AWX permet de faire des lien avec des LDAP, nous nous en servirons ainsi, vous pourrez donc effectuer des actions, comme en entreprise, depuis des comptes AD, et non forcément des comptes locaux afin d'utiliser les bonnes pratiques !

Concernant l'environnement lui-même, nous vous demandons de bien penser a faire des snapshot des machines à chaque fin de chapitre afin d'avoir une utilisation au plus proche de la réalité. Afin d'avoir un meilleur interface, nous avons décider d'ouvrir les flux entre le VM_MASTER et votre ordinateur, afin de pouvoir consulter AWX depuis votre navigateur personnel.

Modifié le: mercredi 29 novembre 2023, 10:45
Introduction Conteneurisation
1. Introduction à la Conteneurisation
La conteneurisation s'est imposée comme un pilier essentiel de l'informatique contemporaine, procurant une agilité et une efficience sans précédent pour la mise en place et la supervision d'applications. Dans ce chapitre, nous déchiffrerons les fondements de la conteneurisation et son importance au sein du paysage technologique.

a. Qu'est-ce que la Conteneurisation ?
La conteneurisation fait référence à la virtualisation basée sur l'OS, où des applications avec leurs dépendances coexistent dans des espaces isolés dénommés « conteneurs ». Ces derniers englobent le code, les bibliothèques et les configurations, assurant une portabilité et une fiabilité optimales. 

b. Les atouts de la Conteneurisation
La conteneurisation présente de multiples avantages, tels que : - Isolation : Chaque application s'exécute dans un conteneur dédié, prévenant ainsi les interférences avec d'autres programmes. - Portabilité : Les conteneurs garantissent une exécution uniforme sur divers environnements. - Efficacité : Ils sollicitent moins de ressources par rapport aux machines virtuelles traditionnelles. - Mise en service rapide : Les conteneurs peuvent être opérationnels en quelques instants.

c. Conteneurisation vs. Virtualisation
La virtualisation engendre des machines virtuelles autonomes dotées de leur propre OS. En revanche, la conteneurisation utilise l'OS de l'hôte et isole les applications dans des conteneurs. Ces caractéristiques intrinsèques influencent la consommation des ressources, la vitesse de mise en œuvre et l'isolation des logiciels.

2. Démystifier les Principes de Base
Cette section s'attardera sur les principes élémentaires de la conteneurisation, en mettant l'accent sur les composants essentiels qui la sous-tendent.

a. Compréhension des Conteneurs
Les conteneurs sont des modules logiciels épurés qui renferment une application et ses composants, créant un cadre isolé. Ils cohabitent avec le noyau OS de l'hôte tout en opérant de manière autonome.

Exemple YAML d'un conteneur basique :

version: '3'
services:
  web:
    image: nginx:latest
(exemple simple d'un conteneur avec une image NGINX en dernière version)... et oui ! c'est aussi simple que ça)

b. Les Images Conteneurisées
Une image conteneurisée est un blueprint exécutable et allégé, comportant tout le nécessaire pour faire fonctionner une application : code, dépendances, configurations, etc. Les conteneurs naissent de ces images.

Exemple YAML pour élaborer une image conteneurisée :

version: '3'
services:
  db:
    image: mysql:latest
(exemple simple d'un conteneur avec une image mysql en dernière version)

c. Les Entrepôts de Conteneurs
Les entrepôts de conteneurs servent de répertoires centralisés pour sauvegarder, administrer et diffuser des images conteneurisées. Ils simplifient la propagation des images pour leur mise en place sur diverses infrastructures.

Exemple YAML pour extraire une image d'un entrepôt :

version: '3'
services:
  app:
    image: your-registry/your-app:latest
(Vos images peuvent être stockés dans beaucoup d'endroit, nous utiliserons par la suite DockerHub qui peut s'apparenter au Github du container !).
3. Maîtriser Docker & Docker-Compose
Ce chapitre se consacrera aux commandes fondamentales de Docker pour la manipulation des conteneurs, ainsi qu'à l'usage de Docker-Compose pour une gestion harmonieuse des configurations multi-conteneurs.

a. Exploration des Commandes Docker
Docker offre une panoplie de commandes pour orchestrer les conteneurs, les images, les connexions, et bien plus. Voici un aperçu des commandes fréquemment sollicitées :

docker run: Initie un conteneur à partir d'une image.
docker build: Conçoit une image à partir d'un Dockerfile.
docker ps: Liste les conteneurs actifs.
docker stop: Met fin à un ou plusieurs conteneurs.
docker rm: Efface un ou plusieurs conteneurs.
b. Utiliser Docker-Compose
Docker-Compose est un instrument permettant de définir et d'administrer des projets multi-conteneurs. Il se base sur un fichier YAML pour structurer les services, les connexions et les espaces de stockage requis.

Exemple de configuration Docker-Compose :

version: '3'
services:
  web:
    image: nginx:latest
  db:
    image: mysql:latest
Ce code spécifie deux services : "web" s'appuyant sur une image Nginx et "db" sur une image MySQL.

5. Sécurité et Optimisation des Conteneurs
Dans cette section, nous traiterons des mesures de sécurité et des stratégies pour une gestion performante des conteneurs.

a. Sécurisation et Isolation des Conteneurs
Bien que les conteneurs assurent une certaine isolation, des précautions supplémentaires sont nécessaires pour instaurer un cadre sécurisé. Voici quelques recommandations :

Isolation des Ressources: Recourir à cgroup et aux espaces de noms pour délimiter les ressources.
Restreindre les Privilèges: Limiter les droits d'accès des conteneurs pour réduire les vulnérabilités.
Mises à Jour Continues: S'assurer que les conteneurs et les logiciels qu'ils contiennent bénéficient des derniers correctifs de sécurité.
b. Optimisation des Ressources
Une gestion avisée des ressources est primordiale pour maximiser l'efficacité des conteneurs. Quelques bonnes pratiques incluent :

Allocation des Ressources: Établir des plafonds pour l'usage du CPU, de la mémoire, etc.
Répartition de la Charge: Distribuer les requêtes entre différents conteneurs pour éviter la saturation.
c. Veille et Diagnostic des Conteneurs
La surveillance des conteneurs et une intervention rapide en cas de dysfonctionnement sont cruciales. Quelques techniques courantes englobent :

Journalisation: Analyser les journaux des conteneurs pour identifier d'éventuels enjeux.
Contrôles de Santé: Mettre en place des vérifications pour évaluer l'état des conteneurs et entreprendre des actions adaptées en cas d'anomalies.
6. Épilogue
Les conteneurs, avec Docker en tête de proue, ont bouleversé la manière dont les logiciels sont conçus, distribués et exploités. Ils combinent isolation, portabilité et efficacité, tout en instaurant un environnement propice à l'agilité et à l'innovation. Comprendre ces principes est une étape cruciale pour quiconque aspire à exceller dans l'univers technologique contemporain.

Pour information nous utiliserons la technologie Docker comme le présente notre introduction, mais il existe d'autres technologies permettant de faire des conteneurs te que podman qui un équivalent...


1. Introduction au YAML
a. Présentation de YAML
YAML, ou "YAML Ain't Markup Language", est un langage de sérialisation des données centré sur la lisibilité humaine (Wikipédia).Ce dernier est conçu pour faciliter l'échange de données entre systèmes, sa structure est facilement interprétable par les ordinateurs et évidemment les logiciels. c'est selon mon avis personnel, du JSON, sans ponctuations de code, mais seulement avec des indentations mais nous en reparlerons plus bas ! Si vous êtes d'ailleurs adepte du JSON, voici un site permettant de faire de la translation entre ces 2 langages : https://www.json2yaml.com/convert-yaml-to-json

b. Les Bases de la Syntaxe YAML
YAML mise sur l'indentation pour organiser les données. Son format clé-valeur intuitif représente les informations de manière structurée. L'importance de l'indentation, la manière de représenter les listes et l'utilisation du caractère # pour les commentaires sont des aspects fondamentaux de sa syntaxe qui n'est pas plus compliqué que ça !.

De plus, pour ceux qui sont familiers avec le format JSON, YAML peut être considéré comme une version allégée de JSON avec moins de syntaxe. En effet, alors que JSON utilise des accolades et des crochets pour délimiter les objets et les listes, YAML s'appuie sur l'indentation. Cette simplification rend souvent YAML plus lisible, surtout pour des configurations plus longues ou complexes.

Exemple simple en YAML :

individu:
  prenom: Antoine Bonnet
  age: 24
  aptitudes:
    - Python
    - JavaScript
    - SQL
    - Ansible
c. Points Forts de YAML
Lisibilité : Sa conception vise la clarté pour les humains. (à l'inverse du JSON qui paraît plus lourd visuellement).
Richesse : Capable de représenter des structures de données élaborées.
Universel : Compatible avec de nombreux langages de programmation. (Notamment docker et ansible que nous utiliserons par la suite).
Modularité : Favorise la réutilisation avec des références et inclusions.
2. Découverte des Concepts de YAML
a. Types de Données Supportés
YAML peut gérer divers types de données, tels que les textes, nombres, booléens, et bien d'autres.

Exemple illustrant différents types :

texte: "Un exemple de chaîne"
nombre: 12345
verite: true
vide: null
date: 2023-10-30
elements:
  - premier
  - second
dictionnaire:
  cle1: valeur1
  cle2: valeur2
b. Organisation des Données : Listes et Dictionnaires
Listes : Séquences ordonnées.
Dictionnaires : Structures clé-valeur.
Exemple démonstratif :

couleurs:
  - rouge
  - bleu
  - vert
profil:
  prenom: Antoine BONNET
  age: 24
  langages:
    - Python
    - JavaScript
c. Ancres et Alias : Optimisation et Réutilisation
Avec les opérateurs & et *, YAML facilite la réutilisation de portions de code.

Exemple pratique :

referent: &ref001
  prenom: Antoine BONNET
  age: 24
collègue: *ref001
3. YAML et la Conteneurisation
a. YAML pour la Configuration
Favorisé en conteneurisation, YAML décrit configurations, variables, ports et autres... Comme vous avez pu le constaterdans notre introduction à Docker, YML fait partie des langages utilisé par cette technologies de conteneurisation.

Exemple d'un service WEB supporter par NGINX avec des paramètres spécifiques :

version: '3'
services:
  webapp:
    image: nginx:latest
    ports:
      - "8080:80"
    env:
      - MODE=production
(Nous pouvons vour sur cette exemple ci-dessus que nous avons utilisé des alias, des listes en clé valeurs.)

b. Service et Application avec YAML
YAML décrit aussi les services et applications dans les conteneurs, du choix de l'image aux dépendances.

Exemple avec Docker Compose :

version: '3'
services:
  monapp:
    image: app_derniere_version:latest
    ports:
      - "8000:8000"
    volumes:
      - ./monapp:/monapp
4. L'Essence de YAML dans Ansible
a. Lisibilité et Simplicité
YAML rend les configurations Ansible facilement compréhensibles, éliminant la complexité inutile, il suffit de lire le playbook et cela sera assez intuitif.

Exemple de playbook Ansible qui installe apache.

- nom: Install Apache
  yum:
    nom: httpd
    etat: present
(Ici, la règle demander à ansible est simple, le service "httpd" doit être présent, il va donc vérifier sur la cible, si il est déja présent, alors ansible ne fait rien, si le service n'est pas présent, alors il l'installe).

b. Interopérabilité
La popularité de YAML dans l'automatisation garantit une intégration fluide avec de multiples outils.

c. Flexibilité pour le Provisionnement
YAML capture efficacement des configurations élaborées, rendant les déploiements à grande échelle gérables.

Exemple de playbook Ansible :

- nom: Configuration Serveurs Web
  hôtes: serveurs_web
  tâches:
    - nom: Install Apache
      yum:
        nom: httpd
        etat: present
    - nom: Démarrer Apache
      service:
        nom: httpd
        etat: démarré
L'exemple ici, plus complexe, permet de montrer la puissance d'Ansible, qui va ici installer un service, puis va démarrer ce même service, tout ça sur un groupe d'hôte spécifique, et le plus grand point fort ici: c'est très intuitif ! cela se lirait presque comme une lettre de course !
5. Conseils pour une Utilisation Efficace de YAML avec Ansible
a. Importance de l'Indentation
Des indentations cohérentes rendent votre YAML clair et évitent des erreurs. Espaces, pas de tabulations !

Exemple d'indentation correcte :

tâches:
  - nom: Installer Apache
    yum:
      nom: httpd
      etat: present
    become: oui  (sert ici a avoir les droits administrateur pour exécuter du code).
b. Commenter pour Clarifier
Les commentaires clarifient les sections et facilitent la collaboration.

Exemple :

# Tâche d'installation d'Apache
- nom: Installer Apache
  yum:
    nom: httpd
    etat: present  # Assurez-vous qu'Apache est installé
c. Promouvoir la Réutilisation
Optimisez avec des modèles pour éviter les redondances et assurer la cohérence.

Exemple :

# Modèle pour installation de paquet
- nom: Installer le paquet
  yum:
    nom: "{{ nom_paquet }}"
    etat: present
(En utilisant Ansible, vous vous servirez très souvent de ce terme "{{ x }}" qui vous permettra de déclarer et réutiliser des variables)
6. Exemples d'Utilisation de YAML pour Ansible
a. Créer un Playbook Ansible
YAML permet de définir clairement les tâches et cibles d'un playbook Ansible.

Exemple :

---
- nom: Playbook Illustratif
  hôtes: serveurs
  tâches:
    - nom: Installer Apache
      yum:
        nom:

 httpd
        etat: present
    - nom: Démarrer Apache
      service:
        nom: httpd
        etat: démarré
b. Définir des Variables Ansible
YAML est parfait pour définir des variables dans Ansible, clarifiant les valeurs et facilitant leur gestion. nous pourrons ici définir des valeurs tel que des ports ou encore des noms d'utilisateurs.

Exemple :

---
port_default: 8080
user_default: "admin"
mode: "production"
c. Gestion des Rôles avec Ansible
Définissez des rôles clairs pour les utilisateurs et les groupes, pour maximiser la sécurité et la gouvernance de nos apps.

Exemple :

---
- nom: Ajout Utilisateurs
  utilisateurs:
    - alice
    - bob
Conclusion
Que ce soit pour la conteneurisation ou l'automatisation, YAML est un outil polyvalent. Sa syntaxe claire et intuitive fait de lui un favori pour Ansible et d'autres systèmes. Comprendre ses principes fondamentaux et meilleures pratiques est essentiel pour une utilisation optimale.

YAML est au cœur d'Ansible. Il est utilisé pour définir les playbooks, les rôles et autres artefacts d'Ansible, ce qui en fait un élément essentiel pour automatiser le provisionnement, la configuration et le déploiement.

Pour maîtriser pleinement YAML dans le contexte d'Ansible, la pratique est essentielle. Nous vous ferons pratiquer ce langage via quelques petits exercices sympathiques afin que vous puissiez évaluer vos connaissances... sourire

Introduction à Ansible
# [1] Présentation d'Ansible

Qu'est-ce qu'Ansible?

Ansible, c'est un outil d'automatisation IT open-source très repandue qui permet d'automatiser des tâches par exemple de la configuration de serveurs, du déploiement d'applications et de la gestion de l'infrastructure. Contrairement à d'autres outils d'automatisation, Ansible est conçu pour être minimaliste et facile à utiliser (via une logique assez simpliste de description du besoin). Il utilise un langage de description simple à lire pour l'humain,le YAML, qui permet de définir les tâches d'automatisation.



Pourquoi utiliser Ansible?

Ansible offre une approche simple et efficace pour automatiser les tâches sans nécessiter de scripts complexes ou de langages de programmation spécialisés, eh oui ! seul une "description" en YAML suffit a lefaire fonctionner .
Avantages d'Ansible

Facilité d'utilisation : Ansible utilise YAML pour définir les tâches d'automatisation.
Agentless : Contrairement à d'autres outils, Ansible n'a pas besoin d'agents installés sur les machines cibles, il agit depuis un serveur master qui effectue des tâches sur sa cible (il a seulement besoin d'une clé ssh, et de python).
Extensible : Ansible dispose d'une vaste bibliothèque de modules pour gérer différents systèmes et services, et comme sur Docker-Hub, Ansible-Galaxy propose des rôles clé en mains créer par la communeauté.


Exemple: Imaginons que tu souhaite installer HTTPD sur un serveur. Avec Ansible, ça pourrait ressembler à ceci en YAML:

---
- name: Installer HTTPD
  hosts: serveurs_web
  tasks:
    - name: Installer le paquet httpd
      yum:
        name: httpd
        state: present
Architecture et composants
Nœuds de contrôle: Il s'agit de la machine sur laquelle Ansible est installé et à partir de laquelle les commandes sont exécutées, nous pouvons aussi l'appeler le Master. Le nœud de contrôle se connecte aux nœuds gérés via SSH, sans nécessiter d'agent sur les machines distantes, les cibles ont parfois besoin de python quand il est nécesssaire de faire tes tâches complexes.

Nœuds gérés: Ce sont les machines sur lesquelles les tâches Ansible sont exécutées. Elles sont définies dans l'inventaire Ansible (fichier inventaire.ini par exemple).

Modules: Les modules Ansible sont des unités de code qui exécutent des tâches spécifiques. Par exemple, le module yum est utilisé pour gérer les paquets sur les systèmes Red Hat, tandis que le module apt est utilisé pour les systèmes Debian (ils sont directement a écrire dans vos playbook, selon la distribution de votre cible).

Inventaire: L'inventaire est un fichier qui contient la liste des nœuds gérés . Il peut être statique (fichier texte) ou dynamique (script ou service externe par exemple).

Inventaire Ansible
Hôtes et groupes: Dans l'inventaire, vous pouvez définir des hôtes individuels ou les regrouper pour une gestion plus facile.

Inventaires statiques: Fichiers texte simples qui listent les nœuds gérés, généralement en format INI ou YAML.

Inventaires dynamiques: Pour les environnements plus complexes ou changeants avec des varaibles, Ansible peut utiliser des scripts ou des services externes pour générer les inventaires.

Introduction à Ansible

[2] Hôtes et groupes
Sur Ansible, les hôtes ou cibles sont les machines sur lesquelles vous souhaitez exécuter des commandes ou installer des packets, applications ou autre. Les hôtes sont définis dans l'inventaire Ansible. Pour faciliter la gestion, vous pouvez regrouper plusieurs hôtes en groupes. Par exemple, tous vos serveurs web peuvent être regroupés sous le nom "web" et vos bases de données sous le nom "db", et ce à l'infini selon vos projet .

Exemple:

Supposons que vous ayez trois serveurs web et deux bases de données:

[web]
webserver_a.example.com
webserver_b.example.com
webserver_c.example.com

[db]
dbserver1.example.com
dbserver2.example.com

#vous pouvez y mettre l'adresse IP cible mais cela n'est pas une bonne pratique, le DNS doit toujours être prioritaire !!
Inventaires statiques et dynamiques
Inventaires statiques: Fichiers texte simples qui listent les nœuds gérés, généralement en format INI ou YAML. Ces fichiers sont faciles à écrire et à comprendre, mais peuvent ne pas être idéaux pour des environnements dynamiques où les machines sont fréquemment ajoutées ou supprimées, pour ça, nous utilisons des Inventaires dynamiques.

Inventaires dynamiques: Pour les environnements plus complexes ou changeants, Ansible peut utiliser des scripts ou des services externes pour générer l'inventaire. Par exemple, si vos serveurs sont dans AWS, un script d'inventaire dynamique peut interroger AWS pour obtenir la liste des instances EC2, puis remplir notre fichier d'inventaire à l'aide de l'output du script.

Commandes Ad-hoc
(eh non, ce chapitre ne parlera pas du Capitaine Haddock, mais bien des commandes Ad-Hoc d'Ansible) 

Les commandes ad-hoc... Ce sont les commandes Ansible que vous pouvez exécuter de manière ponctuelle pour effectuer une tâche simple comme faire un ping, sans écrire un playbook. Elles sont utiles pour des tâches rapides, mais pour des tâches plus complexes ou répétitives, il est préférable d'utiliser des playbooks, ou bien même un rôle !

Exemple:

Pour vérifier l'uptime de tous vos serveurs web, pas besoin de playbook, faites une commande ah-hoc:

ansible web -i inventory.ini -m command -a "uptime"
Ici, -i spécifie l'inventaire, -m spécifie le module à utiliser (dans ce cas, "command") et -a spécifie les arguments à passer au module.

Il existe d'autres commandes ad-hoc utiles comme le ping de tous les hôtes, l'obtention d'informations sur l'espace disque, le redémarrage des serveurs, l'installation de paquets et la copie de fichiers vers des hôtes.

Ping tous les hôtes:

ansible all -i inventory.ini -m ping
La commande vérifie la connectivité de tous les hôtes définis dans l'inventaire.

Obtenir des informations sur l'espace disque:

ansible web -i inventory.ini -m command -a "df -h"
La commande affiche l'espace disque sur tous les serveurs web.

Redémarrer tous les serveurs d'une base de données:

ansible db -i inventory.ini -m command -a "/sbin/reboot"
Installer un paquet sur des serveurs Debian/Ubuntu:

ansible web -i inventory.ini -m apt -a "name=nginx state=present"
La commande installe le serveur web nginx sur tous les serveurs web qui utilisent Debian ou Ubuntu.

Copier un fichier vers des hôtes:

ansible web -i inventory.ini -m copy -a "src=/local/path/file.txt dest=/remote/path/file.txt"
La commande copie un fichier local vers un chemin spécifié sur les serveurs web.

Commande Ad-hoc à travers Ansible: Exécution d'une commande Ad-hoc avec Ansible

[3] Modules Ansible
Présentation des modules
Qu'est-ce qu'un module?
C'st une unité de code qui exécute une tâche spécifique donné. Chaque module est conçu pour être idempotent, donc il peut être exécuté plusieurs fois sans changer le résultat final, à moins que quelque chose n'ait changé sur le système cible (OK/CHANGED/ERROR).

Pourquoi utiliser des modules?
Les modules encapsulent des tâches spécifiques, en fournissant une interface pour effectuer des opérations courantes.De ce fait, vous n'avez pas besoin de connaître les détails spécifiques de la façon dont une opération est effectuée sur chaque OS ou plateforme. Par exemple, le module package peut être utilisé pour installer un logiciel, que vous soyez sur un système utilisant apt, yum, ou un autre gestionnaire de paquets, cela arrivera à la même finalité, Ansible, étant intelligent va pouvoir savoir quelle commande utiliser en back-end.

Types de modules
Il existe des centaines de modules Ansible pour gérer presque tous les aspects de votre environnement, des opérations de base du système d'exploitation, la gestion des services cloud, la gestion des bases de données, et bien plus encore. Comme expliqué précédemment, sur Ansible-Galaxy, vous pouvez trouver playbook, rôle et autre créer par la communeauté, et évidemment, certains modules créer par la communeauté peuvent vous servir !!

Utilisation des modules populaires
module apt
Utilisé pour gérer les paquets sur les systèmes Debian/Ubuntu.
Exemple : Pour installer le paquet nginx :

- name: Installer nginx
  apt:
    name: nginx
    state: present
module yum
Utilisé pour gérer les paquets sur les systèmes Red Hat/CentOS.
Exemple : Pour installer le paquet httpd :

- name: Installer httpd
  yum:
    name: httpd
    state: present
module copy
Copie des fichiers depuis le nœud de contrôle vers les nœuds gérés.
Exemple : Pour copier un fichier index.html vers un serveur web :

- name: Copier index.html
  copy:
    src: /local/path/index.html
    dest: /var/www/html/index.html
module file
Gère les fichiers et les propriétés des fichiers.
Exemple : Pour s'assurer qu'un répertoire /data existe :

- name: Assurer que le répertoire /data existe
  file:
    path: /data
    state: directory
module service
Gère les services sur les systèmes d'exploitation qui utilisent des systèmes d'init comme systemd, upstart, etc.
Exemple : Pour s'assurer que le service nginx est démarré :

- name: Démarrer le service nginx
  service:
    name: nginx
    state: started
Modules Ansible et leur utilisation: Modules Ansible

[4]Les Playbooks
Structure d'un playbook
Le playbook Ansible est un fichier en YAML qui va définir une série de tâches à exécuter sur nos cibles. Chaque playbook est composé de un ou plusieurs "play". Chaque "play" définit un ensemble de tâches qui vont être à exécuter sur mon ou mes hôtes.

La structure typique d'un playbook est la suivante:

---
- name: Nom du play
  hosts: groupe_d_hotes
  tasks:
    - name: Nom de la tâche 1 #comme exepliquer il peut y en avoir plusieurs selon le besoin
      module:
        paramètre1: valeur1
        paramètre2: valeur2
Exemple:

Supposons que vous souhaitiez installer NIGNX sur un groupe de serveurs web. Votre fichier d'inventaire inventaire.ini pourrait ressembler à ceci:

[web]
webserver1.example.com
webserver2.example.com
webserver3.example.com
Et votre playbook installer_NGINX.yml serait:

---
- name: Installer HTTPD sur les serveurs web
  hosts: web
  tasks:
    - name: Installer le paquet httpd
      yum:
        name: httpd
        state: present
>Nous définissons nos cible sous le groupe "web", puis dans notre playbook, nous indiquons que nos hosts seront le groupe cible.
Création et exécution de playbooks
Création: Il s'agit là d'un exemple de création, il n'est pas a réaliser maintenant, des exercices viendront en fin de chapitre. 1. Commencez par créer un fichier .yml ou .yaml pour le playbook puis un fichier .ini pour l'inventaire. 2. Utilisez un éditeur decode/texte de votre choix pour écrire votre playbook et votre inventaire en suivant les structures mentionnées ci-dessus. 3. Sauvegardez les fichiers.

Exécution: Pour exécuter un playbook en utilisant un inventaire spécifique, utilisez la commande ansible-playbook suivie du nom du fichier playbook et de l'option -i pour spécifier l'inventaire:

ansible-playbook -i inventaire.ini installer_NGINX.yml
Création et l'exécution d'un playbook Ansible avec un inventaire spécifique: Création et exécution d'un playbook Ansible avec inventaire

[5] Gestion des Variables
Définition et utilisation des variables
Qu'est-ce qu'une variable?
Dans Ansible, une variable est une étiquette associée à une valeur, qui va généralement être utilisée pour personnaliser le comportement des playbooks et des rôles (extrmement fréquent en industrialisation). Les variables permettent de rendre les playbooks réutilisables et de s'adapter à différents environnements ou configurations. > cela permet entre-autre de ne pas avoir a modifier les playbook à la source, une bonne pratique est de créer un fichier de variables spécifique.

Comment définir une variable?
Les variables peuvent être définies de plusieurs manières:

Directement dans les playbooks (clé-valeur).
Dans des fichiers d'inventaire.
Dans des fichiers de variables externes (meilleur pratique pour de l'industrialisation).
Passées en ligne de commande lors de l'exécution d'un playbook.
Exemple:

---
- hosts: web
  vars:
    http_port: 80
    max_clients: 200
  tasks:
    - name: assurez-vous que le port HTTP est configuré
      template:
        src: templates/httpd.conf.j2
        dest: /etc/httpd/conf/httpd.conf
Dans l'exemple, les variables http_port et max_clients sont définies et utilisées dans le playbook directement.

vars:
  nom_utilisateur: admin
Ou dans un fichier d'inventaire:

[web]
webserver1.example.com http_port=80
Une fois qu'une variable est définie, elle peut être utilisée dans un playbook en l'entourant de doubles accolades {{ }}. Par exemple:

- name: Créer un utilisateur
  user:
    name: "{{ nom_utilisateur }}"
    state: present
Priorité des variables
La priorité des variables est important dans Ansible, car ça détermine quelle valeur sera utilisée si une variable est définie à plusieurs endroits.

Ordre de priorité:

Variables passées en ligne de commande : Elles ont la priorité la plus élevée.
Variables définies dans les rôles : Ces variables ont une priorité inférieure aux variables passées en ligne de commande, mais supérieure aux variables définies dans les playbooks.
Variables définies dans les playbooks : Elles ont une priorité inférieure aux variables définies dans les rôles.
Variables d'inventaire : Elles ont la priorité la plus basse.
image

[6] Vault Ansible
Sécurisation des données sensibles avec Ansible Vault
Dans l'automatisation et la gestion de configuration en IT, la sécurité des données est primordiale. Ansible, conscient de cette nécessité, a introduit Ansible Vault: un mécanisme de chiffrement qui permet de sécuriser n'importe quelle information structurée, qui garantirra ainsi que les données sensibles restent confidentielles même lorsqu'elles sont stockées dans un système de contrôle de version comme Git. (c'est équivalent au Vault de HashiCorp pour les connaisseurs !!).

Pourquoi utiliser Ansible Vault?
- Confidentialité: Ansible Vault chiffre les données à l'aide de l'algorithme AES256, seules les personnes disposant de la clé de déchiffrement peuvent accéder aux données stockés.

Intégration transparente: Même si les données sont chiffrées, Ansible peut les utiliser comme n'importe quel autre fichier lors de l'exécution d'un playbook ou d'un rôle, à condition que le bon password soit donné.

Flexibilité: Vous pouvez chiffrer un fichier entier, ou simplement certaines valeurs à l'intérieur d'un fichier. (ligne ou structure entière).

Utilisation d'Ansible Vault
Chiffrement d'un fichier
Pour chiffrer un fichier entier, utilisez la commande:

ansible-vault encrypt mon_fichier_secret.yml
Lors de l'exécution de cette commande, Ansible Vault vous demandera de fournir un mot de passe. Ce mot de passe sera nécessaire pour toutes les opérations futures sur ce fichier donc retenez le bien !!!

Chiffrement de valeurs spécifiques
Si vous ne souhaitez chiffrer que certaines valeurs à l'intérieur d'un fichier, vous pouvez le faire avec la commande encrypt_string:

ansible-vault encrypt_string 'ma_valeur_secrete' --name 'nom_de_la_variable'  #va chiffrer seulement la chaîne de caractère souhaitée)
Déchiffrement d'un fichier
Si vous avez besoin d'accéder au contenu d'un fichier chiffré, vous pouvez le déchiffrer temporairement:

ansible-vault decrypt mon_fichier_secret.yml
Exécution d'un playbook contenant des données chiffrées
Pendant l'exécution d'un playbook qui utilise du Vault, vous devez fournir le mot de passe précédent. Il existe plusieurs méthodes pour le faire, mais la plus courante est d'utiliser l'option --ask-vault-pass:

ansible-playbook mon_playbook.yml --ask-vault-pass
D'après la documentation officielle
Processus de chiffrement, de déchiffrement et d'utilisation des données avec Ansible Vault: Processus Ansible Vault

[7] Rôles Ansible
Structure d'un rôle
Un rôle Ansible est une structure pré-définie permettant d'organiser les tâches et autres données de manière logique. Il est conçu pour être entièrement autonome, ou, avec d'autres rôles, formant une unité de déploiement complète. Les rôles réduisent la duplication et facilitent la réutilisation, ce qui permet de diviser la configuration complexe en composants réutilisables, sur Ansible, il s'agit d'un point très important, les rôles c'est la vie !

Qu'est-ce qu'un rôle concrètement?
Un rôle est une façon d'automatiser, de configurer et d'organiser un système. Il est divisé en plusieurs composants : les tâches, les gestionnaires, les fichiers, les modèles, etc., qui définissent le comportement et les états souhaités pour une cible ou un groupe de machines.

Comment créer un rôle?
Pour créer un rôle, utilisez la commande ansible-galaxy:

ansible-galaxy init nom_du_role
Cette commande crée une structure de dossiers pour le rôle avec des dossiers et des fichiers prédéfinis, il vous suffit de faire un tree . pour la visualiser.

Explication des dossiers
tasks: Contient la liste principale des tâches à exécuter par le rôle.

Définition: Les tâches sont les actions que Ansible exécutera pour atteindre un état définit.
Exemple: Installer un paquet, démarrer un service, etc.
handlers: Contient des gestionnaires, qui sont des tâches déclenchées par d'autres tâches.

Définition: Les gestionnaires sont similaires aux tâches, mais ne s'exécutent que si une tâche les notifie. (multitasking)
Exemple: Redémarrer un service si un fichier de configuration a été modifié. (if/then)
files: Contient des fichiers qui doivent être déployés par le rôle.

Définition: Ces fichiers sont copiés tels quels, sans modification.
Exemple: Fichiers binaires, images, etc.
templates: Contient des modèles qui peuvent être déployés par le rôle.

Définition: Les modèles sont des fichiers qui peuvent être modifiés par Ansible avant d'être déployés.
Exemple: Fichiers de configuration avec des variables.
vars: Contient des variables définies pour le rôle.

Définition: Ces variables sont utilisées pour personnaliser le comportement du rôle.
Exemple: Version d'un paquet à installer.
defaults: Contient les valeurs par défaut des variables pour le rôle.

Définition: Ces valeurs sont utilisées si l'utilisateur ne fournit pas de valeur.
Exemple: Port par défaut pour un service.
meta: Contient des métadonnées sur le rôle, comme les dépendances.

Définition: Informations sur le rôle, comme l'auteur, la licence, etc.
Exemple: Autres rôles requis pour que ce rôle fonctionne correctement.
voici un exemple au format tree, puis en diagramme:

image

Structure d'un Rôle Ansible

[8] Bonnes Pratiques Ansible
Organisation du code Ansible
L'organisation du code va être essentielle pour garantir la lisibilité, la maintenabilité et la réutilisabilité du code contenu dans tes playbooks. Alors pense à ça:

Modularité:

Utilisation des rôles: Les rôles vont te permettre de regrouper les tâches, les variables, les fichiers et d'autres éléments en une unité. ça facilite la réutilisation du code et garantit que chaque rôle a une responsabilité unique, ce sera donc facilement ré-utilisable.
Réutilisation du code: Comme expliqué précédemment, évitez de dupliquer le code. Si une tâche ou une fonction est utilisée à plusieurs endroits, transforme là en rôle ou en tâche incluse.
Clarté:

Commentaires explicatifs: Utilise des commentaires pour expliquer le but de certaines tâches ou décisions, pour les rôles, met le chemin du code, dans le titre des tasks ain de savoir ou tu en ai lors du run.
Éviter la complexité inutile: Si une tâche peut être accomplie de plusieurs manières, choisissez la plus simple, ne l'utilisez qu'une seule fois, pour le reste, faites des boucles !!
Conventions de nommage
Les conventions de nommage vont t'aider à garantir que le code est compréhensible et cohérent.

Variables:

Utiliser des noms descriptifs: Les noms de variables doivent indiquer clairement leur utilisation ou leur valeur, la forme doit être sous la forme x-x #et ce, en minuscule.
Éviter les abréviations: Sauf si elles sont largement reconnues, évitez les abréviations pour garantir la clarté.
Fichiers et dossiers:

Utiliser des tirets pour séparer les mots: Par exemple, user-management.yml plutôt que usermanagement.yml.
Style
Le style de code est tout aussi important que l'organisation et les conventions de nommage.

Indentation:
Utiliser des espaces plutôt que des tabulations: Cela garantit que le code est affiché de manière cohérente sur différentes plateformes et éditeurs (espace de 3 par 3 sur Ansible).
Bonnes pratiques Ansible:

Bonnes Pratiques Ansible

[9] Conclusion
Résumé des points clés
Au cours de cette session, nous avons couvert plusieurs aspects essentiels d'Ansible, notamment:

Introduction à Ansible: Sa vue d'ensemble d'Ansible et de ses capacités.
Architecture et composants: Comprendre les éléments fondamentaux qui composent Ansible.
Inventaire: La manière dont Ansible gère et organise les hôtes.
Commandes Ad-hoc: L'exécution de commandes simples sans avoir à écrire un playbook.
Modules: Les blocs de construction utilisés pour effectuer des tâches dans Ansible.
Playbooks: Comment automatiser des tâches avec Ansible en utilisant des playbooks.
Gestion des Variables: Comment définir, utiliser et prioriser les variables.
Vault Ansible: S manière de sécuriser les données sensibles avec Ansible Vault.
Rôles Ansible: Comment organiser vos playbooks et réutiliser le code.
Bonnes Pratiques: Les meilleures pratiques pour écrire et organiser le code Ansible.
Ressources pour aller plus loin
Pour approfondir vos connaissances sur Ansible, voici quelques ressources recommandées:

Documentation officielle Ansible: La source la plus complète et à jour sur Ansible.
Forums et communautés Ansible: Des lieux pour poser des questions, apprendre des autres et pourquoi pas partager des connaissances.
tutoriels: Il existe de nombreux tutoriels qui couvrent Ansible en profondeur.
Apprentissage: Nous vous proposerons quelques petits exercices afin de mettre en application vos connaissances.

Introduction à Github
[1] Introduction à GitHub
1. Qu'est-ce que GitHub?
GitHub est une plateforme qui va permettre d'héberger, de partager et de collaborer sur des projets de code. Il s'agit de la plateformes la plus populaire pour le contrôle de versionning et la collaboration, permettant à plusieurs personnes de travailler ensemble sur des projets. (Pour information, et de façon Open-source, il existe Gitlab qui est un Github en locale permettant de retrouver cette aspect collaboratif, ainsi que Git, permettant de faire du versionning).

Il facilite la collaboration entre les développeurs. Grâce à ses fonctionnalités, comme les "pull requests" et les "issues", les équipes vont pouvoir travailler ensemble de manière plus efficace, ils pourront modifier le code de leurs compère en temps réel, émèttre des commentaires, validé ou non leurs mises en applications... mais nous y reviendrons !!! Deplus, ils offrent un espace gratuit pour héberger tes dépôts de code, ce qui permet de sauvegarder et de partager nos projet, de façon publique ou privé. Enfin, Github s'intègre avec de nombreux outils et services, ou encore plugins comme des outils de CI/CD, pour automatiser et améliorer la productivité (certain produit son même directement conçu par GIthub comme Github-action qui permet de créer des workflows automatiquement).

2. Pourquoi utiliser GitHub?
Beaucoup raisons.... Mais les développeurs et les entreprises choisissent d'utiliser GitHub pour certaines d'entres-elles:

Collaboration en équipe: GitHub va faciliter la collaboration en équipe en offrant des outils intégrés qui permettent aux développeurs de travailler ensemble, de discuter des modifications et de résoudre les problèmes, nous y reviendrons plus tard, mais tout est fait pour que ce soit un espace collaboratif.

Versionnage du code: Avec GitHub, chaque modification du code est suivie, ce qui permet de voir qui a fait quoi et quand. ça facilite la détection des erreurs et la collaboration, nous pouvons ainsi remonter dans le temps à la modification x et la remettre en place ou non.

CI/CD: Comme expliquer précédemment, Github permet entre-autre de faire de la CICD, permettant une meilleur productivité !! la CICD peut-être apporter par Github lui-même, avec les workflow github actions, ou bien via des applications tierces qui vont directemment aller questionner github en directe.

3. Différence entre Git et GitHub
Git: C'est un système de contrôle de version distribué. Il permet de suivre les modifications du code réalisé, de créer des branches et de fusionner ces branches (branche production, branche préproduction par exemple). Git fonctionne localement sur l'ordinateur, à l'inverse de github qui est en SaaS.

GitHub: C'est une plateforme basée sur Git qui propose en plus de l'hébergement pour les dépôts Git. En plus des fonctionnalités de Git, GitHub offre aussi des outils pour la collaboration et l'intégration avec d'autres services.

Introduction à GitHub

[2] Interface Graphique de GitHub
1. Présentation de l'interface utilisateur
L'interface utilisateur de GitHub est conçue pour être intuitive et conviviale. Voici quelques éléments clés de l'interface:

Dashboard: C'est la première page que tu vois lorsque tu te connecte à GitHub. Il affiche une vue d'ensemble des activités, des dépôts personnels, des dépôts que tu suis (stars), et plus encore.
image

Profil utilisateur: Ton profil montre ta photo, ta biographie, et une liste de tes dépôts. Pour certains développeur, Github Agit comme un CV, il permet de montrer tes projets.
image

Notifications: tu pourras recevoir des notifications pour les activités liées à tes dépôts ou aux dépôts que tu suis, comme les issues et les pull requests.
image

Paramètres: Dans les paramètres, tu peux configurer ton compte, gérer sa sécurité, tes clés SSH, et d'autres préférences.
image

Bonus: Statistique: tu pourras visionner, en bas de chaque compte Github, le taux de contribution de l'utilisateur, afin de voir si ceui-ci est actif ou non !
image

2. Création d'un nouveau dépôt (repository)
Créer un nouveau dépôt sur GitHub est un processus simple: Répo, et "nouveau"

image

Choix du nom: Choisisser un nom logique pour votre dépôt.
image

Description: Ajouter une brève description pour aider les autres users à comprendre le but de votre dépôt.
image

Visibilité: Tu peux choisir de rendre votre dépôt public (visible par tout le monde) ou privé (visible uniquement par toi et les personnes que tu invite).
image

Initialisation avec README: Il est recommandé d'initialiser votre dépôt avec un fichier README pour fournir des informations sur ton projet. Il va s'agir d'un fichier afficher par défaut dès que quelqu'un cliquera sur votre dépôt, il peut s'agir d'une description plus poussé, et de tutoriels relatif au projet que tu partage.
image

Initialisation avec .gitignore: Cela permettra d'exclure des fichiers inutiles pour l'utilisateur qui souhaite télécharger votre projet, si par exemple tu ne souhaite pas qu'il télécharge votre readme, il te suffira d'ajouter une exception pour l'exclure : *.md.
image

Initialisation avec Licence: tu peux choisir de mettre une licence sur votre projet, afin d'autorisé ou non des choses que les utilisateurs pourraient faire avec votre code (cela permet de se proteger juridiquement).
image

3. Clonage, fork et gestion des branches
Clonage d'un dépôt: Le clonage permet de copier un dépot votre machine locale afin d'avoir le code disponible sans web. tu peux clonner de plusieurs manières en HTTPS, en SSH, en Github CLI, ou bien même avec le client lourd GithubDesktop, et enfin dans un fichier zippé.

image

Forking: Le forking crée une copie personnelle d'un dépôt d'une autre personne. il est par exemple possible de prendre le projet d'un tiers, l'apporter dans ton dépot personnel, potentiellement apporté des modifications dessus, puis après pouvoir faire un commit afin de repousser tes modifications sur le projet de la personne tierce (qui acceptera ou non de le faire).

image

Gestion des branches: Les branches permettent de travailler sur différentes fonctionnalités ou corrections sans affecter la branche principale (Nous appelons ça le versionning. Cela permet de créer des environnement de developpement afin de ne pas créer des débordements d'erreur, ainsi, il est possible de traiter ses actions step by step sans risquer de compromettre certaines partie de votre code.
image

4. Utilisation des issues et des pull requests
Création d'une issue: Les issues sont utilisées pour suivre les bugs, Si tu utilise github pour y stocker ton projet, et que tu te rend compte d'un problème sur ce dernier, tu pourra créer une issue, et expliquer ton problème au mainteneur, celui-ci, si il maintient toujours le projet, pourra la corriger, encore une fois, le collaboratif prend son sens, car des personnes tierce, tu pourras toi-même proposer une correction au code.
image

Assignation et labels: Travaillant à plusieurs sur un projet, si je reçois des issues, je vais pouvoir désigner qui doit s'en occuper afin de répartir les taches, et je vais aussi pouvoir tagger mes issues, si il s'agit d'un bug, d'une duplication d'une demande d'aide ou autre. Par exemple, ci dessous, je vais attribuer l'issue à mon collègue Antoine en taggant celle-ci comme un bug, il recevra donc une notification et pourra commencer à travailler.

image

Création d'une pull request: Dans le cas ou j'ai terminé mon projet, mais que Antoine a travailler sur une nouvelle fonctionnalité, il avait créer une nouvelle branche, il a pu tester son code, il était donc fonctionnel, il demande maintenant a poussé sa nouvelle fonctionnalité en Production, il utilise pour cela un pull-request, il demande enfaite simplement de combiné son code à celui déja présent.

image

Review et merge de la pull request: Une fois la pull request créée, les membres de moi-même ou Antoine peuvent la revoir, la commenter et, une fois approuvée, la fusionner avec la branche principale.
image

image

Recapitulatif Interface graphique de GitHub:

Interface Graphique de GitHub

[3] Ligne de Commande (CLI) avec Git et GitHub
1. Installation et configuration de Git
Avant de commencer à utiliser Git et GitHub via la ligne de commande, Il faut commencer par l'installer en local !

Installation: Selon ton système d'exploitation (Windows, Linux), la procédure d'installation va varier. tu peux télécharger Git depuis le site officiel de Git.

Configuration: Une fois Git installé, configurer votre nom d'utilisateur et votre adresse e-mail github. elle permettrons de relier tes actions à ton compte.

git config --global user.name "Votre Nom"
git config --global user.email "votre.email@example.com"
2. Commandes de base
git clone [URL]: Permet de cloner (copier) un dépôt depuis GitHub vers votre machine locale. Tu te retrouvera donc avec les fichiers/Dossier du projet
image

git add [fichier]: Ajouter des fichiers à l'index pour les préparer pour le prochain commit.

git commit -m 'Message': Créer un nouveau commit avec les fichiers ajoutés à l'index. Le message du commit doit décrire les modifications effectuées.

git push: Envoyer des commits vers le dépôt distant sur GitHub.

git pull: Récupérer les dernières modifications du dépôt distant.

git branch [nom]: Créer une nouvelle branche.

git checkout [nom_branche]: Changer de branche pour travailler sur une fonctionnalité ou une correction spécifique.

3. Création et gestion de dépôts via CLI
git init: Initialiser un nouveau dépôt Git, dans votre répertoire actuel. Cela crée un nouveau sous-répertoire .git qui contient tous les fichiers nécessaires pour le dépôt.

Ajout d'un dépôt distant: Une fois que tu as initialisé un dépôt local, tu peux le lier à un dépôt distant sur GitHub en utilisant la commande:

git remote add origin [URL_du_dépôt_GitHub]
Push vers le dépôt distant: Après avoir effectué tes commits localement, tu peux les envoyer vers le dépôt distant avec:

git push -u origin master
Flux de travail avec Git et GitHub via la ligne de commande:

Flux de travail avec Git et GitHub

[4] Bonnes Pratiques sur GitHub
1. Nommage des dépôts et des branches
Le nommage est important afin de mieux gérer les projets. Je te donne ici quelques tips!

Descriptif et concis : Le nom doit refléter le contenu ou la fonction du dépôt/branche comme par exemple maquette pour dire que c'est la branche de maquette, ou encore par un nom de fonctionnalité que tu t'apprête à créer : branche compteur-de-temps.

Éviter les noms génériques : Les noms comme "test" ou "nouveau" ne sont pas dutout informatifs. Opte pour des noms qui donnent un aperçu du contenu, sans aller dans la branche, tu dois pouvoir avoir une idée de ce qu'elle contient.

Utiliser des tirets pour séparer les mots, et sans ponctuation, ni majuscules : Comme, "documentation-awx" sera préférable à "documentationAWX" ou "Documentation_Awx".

2. Utilisation des messages de commit descriptifs
Un bon message de commit va faciliter la compréhension de l'historique du projet, et évidemment aider ton collègue qui passera derrière toi :

Commencer par un verbe d'action : Par exemple, "Creation la fonctionnalité X" ou "Isolement du bug Y".
image

Limiter à 50 caractères pour le titre : Si tu as besoin d'écrire plus de détails, privilégie le corps du message de commit. Fournis des informations supplémentaires sur ce que fait le commit et pourquoi.
image

3. Gestion des branches
La gestion efficace des branches est essentielle pour le bon développement d'un projet :

Feature branching : Crée une branche pour chaque nouvelle fonctionnalité a ajouter ou modifier. Cela va permettre de travailler sur des éléments spécifiques sans perturber la branche principale qui est généralement la production.

Git flow : C'est un modèle de workflow standardisé qui définit une structure de branches pour tes fonctionnalités, les corrections, les versions, etc. plus d'info ici > https://danielkummer.github.io/git-flow-cheatsheet/index.fr_FR.html

- Ne jamais travailler directement sur la branche 'master' : Comme expliqué précédemment, la branche 'master' doit toujours être stable et aucune opération ne dois être faite sur cette dernière. Donc je le répète, si tu souhaite créer une nouvelle fonctionnalité, ou modifier la principale, créer une nouvelle branche, modifier, et pusher !!
4. Utilisation des labels et des milestones (TAG)
Les labels et les milestones aident à organiser et à prioriser le travail :

Catégoriser les issues : Utiliser des labels pour indiquer le type d'issue (bug, fonctionnalité, amélioration, etc.) cela doit permettre de savoir quelle type de tâche sera attribué au contributeur.

Prioriser les tâches : Les milestones peuvent être utilisés pour regrouper des issues liées à une version ou à une étape spécifique du projet, par exemple, il y aura une priorité sur la correction d'un bug, plutôt que de créer une nouvelle fonctionnalité ! dans ce cas, tu peux priorisé certaines issues.

Suivre l'avancement du projet : Les milestones fournissent une vue d'ensemble de l'avancement vers un objectif particulier, tu as d'ailleur, sur Github, le mode projet qui va permettre d'avoir une vue d'ensemble sur l'avancement du projet, savoir qui doit faire quoi, ainsi que l'état d'avancement de ce dernier (tâche par tâche ou bien global au projet).

image

Les Bonnes pratiques sur GitHub :

Bonnes Pratiques sur GitHub

[5] Sécurité et Clés SSH avec GitHub
1. Qu'est-ce qu'une clé SSH et pourquoi l'utiliser?
SSH est un protocole qui permet d'établir une communication sécurisée entre deux systèmes. Dans le contexte de GitHub, les clés SSH sont utilisées pour établir une connexion sécurisée entre votre ordinateur local et GitHub, sans avoir besoin de saisir votre mot de passe à chaque fois, dans le cas de notre projet, Nous avons par exemple un échange de clé entre le VM_NODE et le VM_MASTER, afin que le master puisse réalisé des actions sur le NODE sans avoir a tapper de mot de passe. our information, le port SSH est le 22 ! mais tu dois sûrement le savoir ahah !

image

Avantages de l'utilisation des clés SSH : - Sécurité renforcée : Les clés SSH offrent un niveau de sécurité plus élevé que les mots de passe simples, composé de beaucoup plus de caractère évidemment, ainsi qu'un count-retry qui permet de bloquer les tentatives de brutforce. - Authentification sans mot de passe : Une fois la clé SSH configurée, tu n'as pas besoin de saisir votre mot de passe à chaque fois que tu interagis avec GitHub, le lien est réalisé par SSH qui vérifie la clé. - Automatisation : Les clés SSH sont essentielles pour les scripts et les automatisations qui nécessitent des interactions fréquentes avec les dépôts, 99.99% sont effectuer comme cela sourire .

2. Génération et ajout d'une clé SSH à GitHub
Génération d'une clé SSH : 1. Ouvre un terminal ou une invite de commande (sur la VM_MASTER en l'occurence). 2. Tape la commande suivante pour générer une nouvelle paire de clés SSH (clé privée et clé publique) : bash ssh-keygen -t rsa -b 4096 -C "votre.email@example.com"

image

Suivre les instructions à l'écran pour choisir un emplacement pour les clés et, éventuellement, (un mot de passe pour sécuriser la clé privée).
Ajout de la clé publique à GitHub : 1. Ouvre le fichier contenant la clé publique (généralement dans ~/.ssh/id_rsa.pub) et copie son contenu (tu peux faire un CAT dessus).

image

Connecte-toi à ton compte GitHub et accède à Settings > SSH and GPG keys.
image

Clique sur New SSH key, donne un titre à votre clé (nom du pc par exemple) et colle le contenu de la clé publique dans le champ prévu à cet effet.
image

image

Clique sur Add SSH key pour ajouter la clé à votre compte GitHub.
image

3. Clonage et push avec SSH
Une fois ta clé SSH ajoutée à GitHub, tu peux cloner des dépôts et pousser des modifications en utilisant SSH au lieu de HTTPS, donc beaucoup plus simple. Plus besoin de renseigner de mot de passe, tout passera par SSH, tu pourra télécharger du code, pousser du code, faire des modifications.... En bref, tout ce qui était faisable depuis le GUI pourra être fait depuis ton p'tit terminal !

Clonage d'un dépôt avec SSH :

git clone git@github.com:NomUtilisateur/NomDepot.git
image

Push des modifications avec SSH : Après avoir effectué des commits localement, tu peux pousser tes modifications vers GitHub en utilisant SSH. La commande reste la même (git push), mais la connexion est établie via SSH, plus besoin d'interface graphique !

image

Processus de génération, d'ajout d'une clé SSH à GitHub, et d'interaction avec GitHub via SSH :

Processus SSH avec GitHub

[6] Collaboration et Contribution avec GitHub
1. Forking et création de pull requests
Le processus de "forking" est une méthode très utilisé pour la contribution dans les projets. Il permet de créer une copie d'un projet externe sur notre propre compte GitHub, d'y apporter des modifications, puis de proposer ces modifications au dépôt original via une "pull request".

Étapes pour forker un dépôt et créer une pull request : 1. Forker le dépôt : Clique sur le bouton "Fork" en haut à droite de la page du dépôt que tu souhaite contribuer. Cela créera une copie du dépôt sur ton compte GitHub (je prend par exemple le projet de mon collègue Bochi auquel je souhaite apporter une modification.

image

image

image

et voilà, je me retrouve avec le projet de Bochi, sur mon compte github !

image

Clone ton fork : Clone le dépôt forké sur ta machine locale pour y apporter des modifications, comme appris précédemment, je vais le cloner pour qu'il se retrouve en local sur mon poste avec la commande git clone git@github.com:R-D-Y/NomDuProjet.git.
image

Apporte des modifications : Une fois le projet en local, libre à toi d'apporter les options souhaités!

Crée une pull request : Retourne à la page du dépôt original et clique sur "New Pull Request". Sélectionne ton fork et la branche sur laquelle tu as travaillé, puis soumets la pull request !!

image

Usage perso ?? : Et oui, après votre forks, si la modification que tu as apporter, est strictement personnel à ton infrastructure, et n'aura aucun plus pour les autres, tu n'est évidemment pas obligé de soumettre un pull request, cette dernière sert uniquement à contribué à un projet, afin de pousser tes modifications pour les autres sourire .
2. Gestion des conflits
Lorsque plusieurs personnes travaillent sur le même code, évidemment, des conflits peuvent survenir. GitHub fournit donc des outils pour identifier et résoudre ces derniers !

Résolution des conflits : 1. Lorsqu'un conflit est détecté, GitHub t'informera dans la pull request.

image

Ouvre les fichiers en conflit et recherche les marqueurs de conflit (<<<<<<<, =======, >>>>>>>).
image

Il suffit de Modifier le code pour résoudre le conflit, puis de supprimer les marqueurs de conflit.
Enfin, Commit et pousse les modifications résolues et le tour est joué !
3. Code reviews et commentaires
Les "code reviews" sont essentielles pour maintenir la qualité du code. Lorsqu'une pull request est soumise, Les membres de l'équipe, les contributeurs, ou bien même toutes personnes suivant ton projet de près ou de loin peuvent donner leurs avis (Comme sur les réseaux sociaux!).

Processus de code review : 1. Examine le code soumis dans la pull request. 2. Si tu as des suggestions ou des corrections, commente directement sur les lignes de code concernées, dans l'exemple ci-dessous, j'avais fais un petit TP sur Terraform, mon professeur, à la suite de ce TP, a examiner contribuer à mon projet (correctionnel), J'ai donc à mon tour, commenter sa proposition !

image

Si tout semble correct, tu peux approuver la pull request. Sinon, demande des modifications avant la fusion. Dans ce même exemple, je ne Mergerais pas la pull request car elle est inutile à mon projet
image

Processus de forking, de création de pull requests, de gestion des conflits et de code reviews sur GitHub :

Processus de Collaboration et Contribution avec GitHub

La collaboration et la contribution sont au cœur de la philosophie de GitHub. En suivant ces étapes et en adoptant les bonnes pratiques, vous pouvez contribuer efficacement à des projets et assurer une qualité de code élevée.

[7] Fonctionnalités Avancées de GitHub
1. GitHub Actions la CI/CD
GitHub Actions est un outil d'automatisation clé en main qui permet de définir des workflows personnalisés pour créer une pipeline directement depuis votre dépôt GitHub. En d'autre terme, Github action permet de faire de la CI/CD...



CI (Intégration Continue) : C'est le fait d'automatiser le processus de vérification de chaque modification apportée au code source (tu te souviens ? les merges ?), en exécutant un ensemble de tests pour s'assurer que le code est correct. Il va permmettre de valider le fait que la modification que tu as apporté n'impacte pas l'environnement de production !

CD (Livraison Continue) : C'est la prochaine étape après l'Intégration Continue. Elle se concentre sur la livraison automatique de code déjà vérifié à la production. Et oui, une fois les tests effectués, pourquoi attendre ? la partie CD va permettre de pousser tes modification directement en production !

Automatisation des workflows : Avec GitHub Actions, tu peux automatiser tous les aspects du développement de votre projet, comme la construction, les tests, le déploiement, etc. tu peux par exemple faire un workflow avec Github action, pourra faires ces actions: dès qu'une modification est apporté au code, il lance des tests automatique, si les tests n'aboutissent pas, il t'envoie un petit mail pour te dire là ou ça coince, sinon, il pousse ton code directement en production ! Dans ce cas précis, il s'agit de CI/CD, l'intégration as été validé, puis le déploiement a été mis en place !

2. Utilisation de GitHub Pages pour tes sites web
GitHub Pages est un service d'hébergement gratuit qui prend votre code HTML, CSS et JavaScript, construit à partir d'un dépôt GitHub, et le transforme en un site web... et oui, Github stock du code, mais pas que ! tu peux aussi t'en servir pour héberger ton site web et ce de façon gratuite, parfait pour faire un petit blog!



Personnalisation des thèmes : GitHub Pages supporte Jekyll, ce qui signifie que tu peux personnaliser l'apparence de ton site en choisissant parmi les thèmes disponibles ou en créant le vôtre, parfait si tu n'est pas un expert du front-end. (pour information Jekyll est un générateur de site statique! comme Wordpress!).
image

Domaines personnalisés ? c'est possible! : Tu peux évidemment ajouter ton propre nom de domaine à ton site GitHub Pages pour lui donner une adresse web professionnelle, oublie le github.TonPseudo.io ! tu pourra très facilement mettre ton nom.prenom par exemple...
3. GitHub Packages
GitHub Packages C'est un service d'hébergement de packages qui te permet d'héberger tes packages de logiciels et de s'en servir comme des dépendances de ton projet ! (un peu comme un requirement.exe) > ICI

image

Partage de packages de code : Tu peux héberger tes packages et les rendres disponibles dans tous les langages de programmation.

Intégration dans github : Évidemment ce dernier s'intègre avec GitHub, dans tes projets, donc tu peux utiliser le même flux de travail pour le code source et les packages. Tout peut-être stocker au même endroit, et de façon all-in-one avoir tout de disponible en 1 git-clone !

Gestion des versions : Tu peux publier de nouvelles versions de tes packages et définir des versions spécifiques comme dépendances dans tes projets. Donc de la même manière que tu créer des branches pour versionner ton projet avec du code, ici, avec tes packages, tu peux forcer a utiliser tel ou tel dépendance, dans tel ou tel version selon le client que tu auras en face... Il est sur Windows ? utilise celles-ci, il est sur MacOS ? utilise celles-là sourire

Les fonctionnalités avancées de GitHub :

Fonctionnalités Avancées GitHub

GitHub va offrire énormément fonctionnalités avancées qui permettent qui permettent de travailler de manière plus efficace, de collaborer avec d'autres et de déployer des projets de manière sécurisée et fiable et surtout, très rapidement. Ces outils, lorsqu'ils sont utilisés correctement et ensemble, peuvent grandement améliorer la productivité des équipes. Il s'agît de la raison principale pour laquelle Github, combinés à ses fonctionnalités, font qu'ils sont leaders sur ce marché.

[8] Conclusion sur GitHub
1. Résumé des points clés
Au cours de cette session, nous avons exploré en profondeur les différentes facettes de GitHub !

Introduction à GitHub : Nous avons découvert ce qu'est GitHub, pourquoi il est essentiel pour travailler en équipe et comment il se distingue de Git.

Interface Graphique : Nous avons navigué à travers l'interface utilisateur de GitHub, afin de comprendre ce qui était possible de faire à partir de l'interface web, et pris connaissance des utilisations de base de ce dernier.

Github CLI : Nous avons abordé les commandes Git essentielles pour la gestion des dépôts (git & push), des commits, des branches, et bien plus encore...

Bonnes Pratiques : Nous avons discuté des méthodes de bonens pratiques pour une bonne utilisation de cet outil, de façon productive et sécurisé.

Sécurité & Clés SSH : Point de vue sur l'importance des clés SSH : pour une connexion sécurisée et surtout plus simple !

Collaboration et Contribution : Nous avons appris comment collaborer efficacement avec d'autres, savoir gérer les conflits, et appris la manière dont nous pouvions contribuer à des projets autant en interne, qu'en Open-Source!

Fonctionnalités Avancées : Nous avons découvert quelques outils proposés par Github tels que GitHub Actions, GitHub Pages, et GitHub Packages. (Il en existe encore beaucoup crois-moi!).

2. Pour aller plus loin...
Pour approfondir tes connaissances sur GitHub, voici quelques ressources utiles :

Documentation officielle et blog : La documentation de GitHub est une ressource inestimable pour comprendre toutes les fonctionnalités de la plateforme. Pour des sujets peut-être spécifique, ou des mises en oeuvre concrète, je te conseil le blog de Stéphane Robert qui m'a aidé plus d'une fois!
Vidéos Youtube : Beaucoup de vidéastes spécialisés en informatique mettent en oeuvre beaucoup de tuto sur Github, même si ce cours servira amplement, rien ne t'empêche de faire de la veille à ce sujet sourire.
- Des soucis ? : Github, ayant une large communeauté, tu n'auras aucun mal à trouver de l'aide, sur le forum interne ou encore sur stackoverflow.
3. GitLab
Alors que nous avons principalement discuté de GitHub dans ce cours, il est également important de mentionner GitLab, c'est une autre plateforme populaire de gestion de code source. GitLab offre des fonctionnalités similaires à GitHub mais se distingue par certaines fonctionnalités, Gitlab est un projet Open-Source et donc gratuit, et ce dernier peut-être installer en local. Sur ce même sujet, il nest pas rare en entreprise d'utiliser Gitlab et github, car sans accès web, Gitlab est un bon remède, parfait pour des serveurs qui n'ont pas d'accès web pour des raisons de sécurités, ceux-ci peuvent par exemple aller chercher des sources sur Gitlab! C'est un autre sujet, nous n'en n'aurons pas besoin pour notre projet, mais n'hésite pas à te renseigner à ce sujet.

4. Exercices pratiques
Pour consolider tes connaissances, il est essentiel de mettre en pratique ce que nous avons pu t'apprendre. Dans la section suivante, nous allons proposer quelques exercices pratiques pour tester et renforcer tes compétences sur GitHub.

Déploiement AWX
Procédure du déploiement de la plateforme
Cette page est dédié pour la procédure de déploiement de la plateforme sur l'infrastructure. Il faut suivre les lignes de commande ci-dessous ou alors de regarder la vidéo.

Premièrement, retournez dans le dossier /home/ansible pour cloner le repo de l'installation :

cd /home/ansible/
Cloner le projet dans votre dossier :

git clone https://github.com/R-D-Y/ansible-awx-course.git
Faire un changement de branche du repo en allant sur la branche "awxinstall" :

git checkout awxinstall
Aller dans le dossier d'installation d'AWX, c'est dans ce chemin ou il y'aura tout les fichiers de configuration pour AWX :

cd /home/ansible/ansible-awx-course/awx/install
Faire une identification en ayant les privilèges root pour la machine en tapant cette commande :

sudo -i
Tapez le mot de passe de la machine.

Copier TOUS les fichiers du repo dans le chemin suivant :

cp * ~/.awx/
Aller sur votre navigateur préféré et taper l'adresse iI Ce rendre dans ce fichier et lancer un docker-compose pour l'installation awx.

cd ~/.awx/
docker-compose up -d
Aller sur votre navigateur préféré exemple : Google Chrome, Firefox, Edge, Opera, Internet Explo...loading et taper l'adresse de la VM dans la barre de recherche http://172.20.10.4/#/home

Vous devez tomber sur cette page la, les identifiants sont admin/admin :

Pour les curieux
Docker-compose
Ce code est une configuration pour déployer une architecture basée sur des conteneurs Docker pour déployer Ansible AWX dans l'infrastructure. Au vu du manque de temps et étant pas le sujet principal d'apprentissage, nous avons choisi de faire le fichier docker-compose afin de facilité l'installation de la plateforme. Cela permet quand même de comprendre l'importance et la facilité des configurations par fichier.

Que fait le docker-compose :

Il définit plusieurs services à exécuter via des conteneurs Docker :

Service rabbitmq:
Ce service utilise l'image ansible/awx_rabbitmq:3.7.4 pour créer un conteneur nommé awx_rabbitmq. Il s'agit d'une instance de RabbitMQ, un gestionnaire de messages utilisé pour la communication interne de l'application. Il est configuré avec des variables d'environnement telles que le virtual host (awx), le nom d'utilisateur (guest), le mot de passe (awxpass), et un cookie Erlang (cookiemonster).

Service memcached:
Utilisant l'image memcached:alpine, ce service crée un conteneur nommé awx_memcached. Memcached est un système de mise en cache en mémoire qui peut améliorer les performances en stockant des données temporaires. Aucune variable d'environnement spécifique n'est configurée pour ce service.

Service postgres:
Ce service utilise l'image postgres:10 pour créer un conteneur nommé awx_postgres. Il s'agit d'une base de données PostgreSQL version 10 configurée pour stocker les données nécessaires au fonctionnement d'AWX. Le conteneur est configuré avec des volumes pour persister les données et des variables d'environnement pour définir l'utilisateur, le mot de passe et la base de données PostgreSQL à utiliser.

Service web:
Ce service utilise l'image ansible/awx_web:9.2.0 pour créer un conteneur nommé awx_web. Il s'agit de l'interface web d'AWX accessible sur le port 80 de l'hôte. Ce service dépend des services RabbitMQ, Memcached et PostgreSQL. Il expose le port 80 de l'hôte vers le port 8052 du conteneur et monte certains fichiers de configuration locaux dans le conteneur.

Service task:
Utilisant l'image ansible/awx_task:9.2.0, ce service crée un conteneur nommé awx_task. Il gère l'exécution des tâches dans AWX et dépend des services RabbitMQ, Memcached, Web et PostgreSQL. Comme le service "web", il monte également certains fichiers de configuration locaux dans le conteneur.

Nginx.conf
Le fichier nginx.conf est une configuration Nginx utilisée pour définir le comportement du serveur web Nginx qui agit comme un proxy pour l'interface web d'AWX. ce fichier de configuration nginx.conf définit les règles, les emplacements et les paramètres de sécurité spécifiques pour le serveur Nginx qui sert d'interface web pour l'application Ansible AWX. Cette configuration est liée au service "web" dans le fichier Docker Compose en spécifiant certains chemins de montage de fichiers de configuration pour Nginx dans le conteneur "awx_web".

Credentiels.py
Ce fichier credentials.py est utilisé par les services définis dans le Docker Compose pour configurer les connexions et les paramètres des services. Il fait référence aux noms des services définis dans le Docker Compose pour établir la communication entre ces services au sein des conteneurs Docker. Les informations de connexion et de configuration dans ce fichier correspondent aux noms et aux paramètres des services spécifiés dans le fichier Docker Compose pour assurer une intégration cohérente et un fonctionnement harmonieux de l'application AWX dans un environnement conteneurisé.

Environnement.sh
Le fichier environnement.sh contient des variables d'environnement qui établissent des connexions et des paramètres pour la base de données PostgreSQL, Memcached et RabbitMQ, nécessaires au fonctionnement de l'application AWX déployée à l'aide du fichier Docker Compose.
Introduction D’AWX
Modifier 
Introduction D’AWX 
                                           
Introduction à Ansible AWX
Ansible AWX est une interface Web open-source développé par Red Hat qui permet de gérer et d'automatiser les tâches de configuration, de déploiement et d'orchestration à l'aide d'Ansible. Il offre une interface conviviale pour gérer vos playbooks, planifier des tâches, suivre l'état des déploiements et bien plus encore.

S'appuyant sur le moteur stratégique d'ansible et une interface graphique, elle intègre mieux la centralisation des modules d'automatisations pour une meilleur visibilité sur les flux. Elle n'est pas simplement une interface pour les développeurs, elle donne aux équipes non formées à l'automatisation un nouveau état d'esprit de développement de leur production.

L'un des principaux avantages d'AWX est sa capacité à créer des flux de travail complexes en reliant plusieurs playbooks et tâches, permettant une automatisation complète et personnalisée. Cette approche modulaire augmente la flexibilité, permettant aux administrateurs système et aux équipes DevOps de concevoir des processus automatisés adaptés à leurs besoins spécifiques dans l'entreprise.

En résumé, Ansible AWX représente une solution d'automatisation complète qui fournit une interface conviviale tout en tirant parti de la puissance d'Ansible pour simplifier et accélérer les opérations informatiques. Qu'il s'agisse de gestion de configuration, de déploiement d'applications ou de gestion d'infrastructure, AWX fournit des solutions évolutives, flexibles et orientées collaboration pour répondre aux défis actuels de l'automatisation informatique.

Avantages d'Ansible AWX
Interface Web pour la gestion des tâches Ansible.
Planification automatisée des tâches.
Suivi de l'historique des tâches et des résultats.
Possibilité de gérer les rôles et les modèles de manière centralisée.
Collaboration d'équipe avec des contrôles d'accès basés sur les rôles.
Permet au personne non technique de toucher au monde de l'automatisation

Introduction :
Bienvenue dans la section des onglets sur AWX ! Nous allons enfin manipuler sur la plateforme, mais pas si vite ! Dans un premier temps, une petite présentation de chacun des onglets. Il n'y a pas la présentation de tous les onglets de la plateforme, sinon on partirait ensemble sur un cours de 30 heures mais une présentation pour les onglets que vous allez utilisé durant cette partie du cours. Bonne lecture sourire

Schéma des couches sur AWX :
Capture d’écran 2024-02-14 123526

Ce schéma montre comment fonctionne AWX, nous avons

Tableau de bord :
En tant que plateforme open source de gestion et d'orchestration automatisées des tâches, elle fournit des tableaux de bord riches en données pour surveiller et gérer efficacement les processus. Les tableaux de bord constituent le point central où les administrateurs et les utilisateurs peuvent obtenir une visibilité complète sur l'état opérationnel de leur infrastructure d'automatisation.

En plus des données mentionnées précédemment, le tableau de bord AWX fournit divers éléments pour une analyse approfondie. Ces composants incluent des graphiques interactifs qui représentent les tendances d'utilisation des ressources telles que la charge du processeur et la mémoire. Ces données permettent aux administrateurs de surveiller de près les performances du système, de prévoir les pics d'utilisation et de planifier des actions pour optimiser les ressources. La section Statistiques des tâches fournit une vue détaillée de l'exécution des tâches. Il fournit des mesures spécifiques telles que le temps d'exécution moyen des tâches, le taux de réussite, les échecs fréquents et les tâches en attente. Ces informations permettent d'identifier les goulots d'étranglement, les erreurs récurrentes ou les tâches qui prennent plus de temps que prévu, ce qui facilite la résolution proactive des problèmes.

Le tableau de bord peut également inclure des indicateurs de performance clés (KPI) personnalisables pour répondre aux besoins spécifiques de l'organisation. Ces KPI peuvent couvrir divers aspects tels que le nombre de nœuds gérés, les mises à jour de configuration, les tendances de l'utilisation des ressources par projet ou par équipe, offrant ainsi une vision granulaire de l'efficacité opérationnelle.

Grâce à l'interactivité du tableau de bord, les utilisateurs peuvent personnaliser les vues en fonction de leurs préférences et de leurs besoins spécifiques. Ils peuvent zoomer sur des plages de temps spécifiques, ajouter des filtres pour afficher des données spécifiques, ou même configurer des alertes pour être informés en temps réel des événements critiques. Outre la surveillance en temps réel, le tableau de bord d'AWX peut également générer des rapports détaillés sur les performances passées. Ces rapports historiques offrent des insights précieux pour évaluer les tendances, identifier les améliorations potentielles et permettre une planification stratégique à long terme pour optimiser les processus d'automatisation.

Pour conclure, le tableau de bord d'AWX constitue un outil essentiel pour les administrateurs et les équipes opérationnelles, offrant une visibilité complète et approfondie sur les performances et la santé du système d'automatisation. Sa capacité à présenter des données détaillées, à fournir des analyses pertinentes et à permettre une réactivité rapide est cruciale pour maintenir un environnement automatisé stable et efficient.

Capture d’écran 2024-01-29 091308

Jobs :
L'onglet jobs dans AWX offre une autre vision des tâches qui ont été exécutées, fournissant une interface détaillée pour gérer et analyser le flux de travail. Il constitue un centre de contrôle essentiel pour les opérations automatisées, permettant aux utilisateurs de gérer, suivre et diagnostiquer les processus en cours ou passés. L'un des aspects fondamentaux de cet onglet est sa capacité à présenter une liste complète de tous les jobs précédemment exécutés, qu'ils aient été lancés manuellement ou de manière planifiée. Cette fonctionnalité permet aux utilisateurs de retracer et d'accéder facilement aux informations sur chaque tâche, offrant ainsi une vue d'ensemble claire de l'historique des opérations.

L'interface de l'onglet jobs propose des fonctionnalités de filtrage avancées, permettant aux utilisateurs de rechercher des jobs spécifiques en fonction de divers critères tels que le nom, l'état d'exécution, la date et l'heure de lancement, voire même en fonction des tags associés aux jobs. Cette capacité de filtrage facilite la gestion des jobs, en offrant un moyen rapide et efficace d'identifier et de sélectionner des tâches spécifiques parmi une liste importante.

En plus de la recherche et du filtrage, l'onglet permet un accès direct aux logs détaillés de chaque job exécuté. Ces logs fournissent une traçabilité complète des actions effectuées, des commandes exécutées, des erreurs rencontrées, et des résultats obtenus. Ainsi, les utilisateurs peuvent non seulement surveiller la progression d'une tâche en temps réel, mais également rétroactivement analyser les informations pour diagnostiquer tout problème éventuel

Pour conclure, l'onglet "Jobs" dans AWX offre une plateforme centralisée, puissante et intuitive pour gérer efficacement les tâches automatisées. En fournissant des informations détaillées, des outils de filtrage avancés, un suivi en temps réel et des capacités de diagnostic approfondies, il facilite la surveillance, la gestion et l'optimisation des processus automatisés, contribuant ainsi à une gestion globale plus efficace et à la résolution proactive des problèmes.

Capture d’écran 2024-01-29 091354

Scheduling :
L'onglet Scheduling, représente une fonctionnalité essentielle pour automatiser et planifier des tâches au sein de l'infrastructure. Cette section permet une gestion minutieuse du temps et des déclencheurs pour l'exécution récurrente de jobs ou de workflows. Voici une analyse plus approfondie de cette fonctionnalité :

Automatisation des tâches récurrentes : L'une des principales fonctions du module de planification dans AWX est de permettre aux administrateurs de configurer des jobs à exécuter automatiquement selon des plages horaires prédéfinies, des jours spécifiques, voire même à des intervalles réguliers.

Flexibilité dans la planification : Les utilisateurs ont la liberté de définir des horaires précis pour lancer des jobs. Par exemple, ils peuvent programmer des activités à des heures spécifiques pendant la journée, des jours de la semaine ou des mois précis, ce qui offre une grande flexibilité pour adapter l'automatisation aux besoins spécifiques de l'entreprise.

Gestion avancée du calendrier : La fonction de planification dans AWX permet également une gestion avancée du calendrier. Cela comprend la capacité à gérer des événements spéciaux ou des jours fériés, ainsi que la possibilité d'ajuster les tâches en conséquence pour éviter les conflits ou pour garantir leur exécution sans interruption.

Intégration avec d'autres systèmes : AWX peut être intégré à d'autres applications ou systèmes externes, ce qui permet de synchroniser les planifications avec d'autres outils utilisés dans l'entreprise. Cela offre une synchronisation efficace et une collaboration entre différentes plateformes.

Logging et suivi des tâches : Lorsque les jobs sont planifiés et exécutés, AWX offre des fonctionnalités de logging avancées pour permettre aux administrateurs de suivre l'état et les résultats des tâches automatisées. Les rapports détaillés peuvent être consultés pour analyser les performances et identifier les problèmes éventuels.

Gestion des erreurs et des exceptions : En cas d'échecs ou d'erreurs lors de l'exécution des tâches planifiées, AWX offre des options pour gérer ces exceptions. Les administrateurs peuvent configurer des notifications d'alerte pour être informés des problèmes ou définir des actions spécifiques à prendre en cas d'échec.

Sécurité et contrôle d'accès : La fonction de planification dans AWX est également intégrée aux mécanismes de sécurité et de contrôle d'accès de la plateforme. Cela garantit que seuls les utilisateurs autorisés peuvent modifier ou créer des tâches planifiées, assurant ainsi la sécurité des opérations automatisées.

La section de planification dans AWX offre une solution robuste et complète pour l'automatisation des tâches, permettant aux entreprises de gérer efficacement leurs processus, d'améliorer l'efficacité opérationnelle et de réduire la dépendance à l'égard des interventions manuelles pour des tâches récurrentes.

Capture d’écran 2024-01-29 091410

Modèle :
L'onglet Modèle ou template dans AWX offre un espace structuré pour la création et la gestion de modèles de configuration. Ces modèles constituent des configurations prédéfinies pour les jobs Ansible, permettant ainsi aux utilisateurs de définir des paramètres, des variables et des options standardisées pour simplifier la répétition de tâches complexes ou récurrentes.

Lorsque vous créez un modèle dans cet onglet, vous définissez essentiellement un ensemble de paramètres et d'options qui peuvent être réutilisés pour exécuter des jobs Ansible spécifiques. Ces modèles agissent comme des patrons ou des modèles de base pour la configuration de ces jobs, facilitant ainsi la création de tâches similaires ou connexes sans avoir à redéfinir constamment les mêmes paramètres.

Dans un modèle AWX, vous pouvez spécifier divers éléments. Cela inclut des variables, qui sont des valeurs dynamiques pouvant être modifiées à chaque exécution du job, permettant ainsi une flexibilité dans l'adaptation des opérations en fonction des besoins spécifiques de chaque instance d'exécution. Ces variables peuvent être des données de configuration, des chemins de fichiers, des adresses IP, ou toute autre information nécessaire à l'exécution du job.

En plus des variables, les modèles peuvent également inclure des options de configuration, telles que des choix de playbook Ansible à exécuter, des inventaires à utiliser pour cibler des hôtes spécifiques, des limites sur les ressources à allouer pour l'exécution du job, des paramètres d'environnement, etc.

La création de modèles dans l'onglet "Modèle" offre un certain nombre d'avantages significatifs. Cela permet une gestion centralisée des configurations récurrentes, garantissant ainsi une uniformité et une cohérence dans l'exécution des tâches. En utilisant des modèles, les utilisateurs peuvent réduire les erreurs humaines potentielles en évitant de répéter manuellement la configuration à chaque exécution de job, car les paramètres sont déjà définis dans le modèle.

En résumé, l'onglet Modèle dans AWX fournit un moyen pratique de créer des modèles de configuration réutilisables pour les jobs Ansible, facilitant ainsi la gestion, la standardisation et la simplification des opérations récurrentes tout en offrant une flexibilité pour personnaliser les variables et les options pour chaque exécution individuelle.

Capture d’écran 2024-01-29 091437

Informations d'identification :
L'onglet Informations d'identification dans AWX, qui est une interface web open-source pour la gestion de l'automatisation des tâches IT, joue un rôle crucial dans la sécurisation des données sensibles utilisées dans les processus d'automatisation. Cette section constitue une partie essentielle de la plateforme, car elle permet de stocker et de gérer de manière sécurisée les informations sensibles, telles que les clés SSH, les mots de passe, les jetons d'API, et bien d'autres types de données confidentielles nécessaires pour l'exécution de tâches automatisées.

AWX offre un système d'informations d'identification centralisé, permettant aux administrateurs de stocker ces données sensibles de manière cryptée et de les associer à des emplois spécifiques. Cette approche permet de garantir un accès sécurisé aux ressources externes, tout en assurant une gestion fine des autorisations pour les différents utilisateurs et les différentes équipes.

Les informations d'identification peuvent être catégorisées en plusieurs types, en fonction de leur utilisation. Par exemple, les clés SSH sont souvent utilisées pour établir des connexions sécurisées entre des serveurs, et leur stockage sécurisé dans AWX garantit un accès protégé lors de l'exécution de tâches automatisées nécessitant ces clés. De même, les mots de passe, qu'ils soient liés à des comptes système, des bases de données, ou d'autres ressources, sont également stockés de manière sécurisée dans cette section pour une utilisation sécurisée dans les automatisations.

AWX fournit des mécanismes avancés de gestion des informations d'identification, notamment la rotation automatique des mots de passe, la limitation des accès basée sur des rôles et des permissions, ainsi que des fonctionnalités de journalisation pour suivre l'utilisation et les modifications apportées aux informations sensibles.

La sécurité des informations d'identification est une préoccupation majeure, et AWX intègre des pratiques robustes en matière de cryptage et de protection des données, telles que le stockage des informations sensibles sous forme chiffrée dans sa base de données, limitant ainsi l'accès direct à ces données même pour les administrateurs de la plateforme.

En somme, la section Informations d'identification dans AWX représente un coffre-fort numérique essentiel pour stocker et gérer de manière sécurisée les données sensibles utilisées dans les processus d'automatisation, garantissant ainsi une exécution sécurisée des tâches automatisées tout en préservant la confidentialité et l'intégrité des informations sensibles.

Capture d’écran 2024-01-29 091448

Projet :
L'onglet Projet dans AWX, joue un rôle central dans la gestion des référentiels Git et des ressources nécessaires à l'exécution des tâches d'automatisation. Ce tableau de bord offre une vue exhaustive et organisée de tous les projets liés à des référentiels Git spécifiques.

Chaque projet répertorié est associé à un référentiel Git. Ces référentiels servent de dépôts centralisés où sont stockés les playbooks, les fichiers de configuration, les rôles Ansible et d'autres ressources nécessaires à l'exécution des tâches automatisées via Ansible.

L'intégration des référentiels Git dans AWX est cruciale pour plusieurs raisons. Premièrement, cela permet une gestion centralisée des ressources. Les équipes peuvent collaborer plus efficacement en travaillant sur les mêmes fichiers et en bénéficiant des fonctionnalités de versionnement offertes par Git, ce qui garantit la cohérence et la traçabilité des changements.

De plus, la fonction de synchronisation des projets est essentielle. Elle permet de récupérer les dernières mises à jour depuis les référentiels Git, assurant ainsi que les versions utilisées pour l'exécution des jobs Ansible sont à jour et reflètent les dernières modifications apportées au code source. Cela garantit une exécution fiable et conforme aux changements apportés dans le code.

L'onglet Projet offre des fonctionnalités avancées de gestion des projets. Les utilisateurs peuvent configurer des variables d'environnement spécifiques à chaque projet, définir des autorisations d'accès granulaires pour les membres de l'équipe et planifier des synchronisations régulières avec les référentiels Git externes pour maintenir la cohérence et la pertinence des fichiers.

En outre, la vue détaillée dans cet onglet permet aux administrateurs et aux utilisateurs d'AWX de surveiller l'état de chaque projet, de vérifier les erreurs éventuelles lors de la synchronisation et de résoudre rapidement tout problème pouvant survenir lors de la récupération des données depuis le référentiel Git.

Globalement, l'onglet Projet constitue le point central pour la gestion, la synchronisation et la surveillance des référentiels Git dans AWX. Il offre un environnement convivial pour les équipes travaillant avec Ansible, garantissant une gestion efficace des ressources nécessaires à l'automatisation des infrastructures et des processus IT.

Capture d’écran 2024-01-29 091500

Inventaires :
L'onglet inventaire, dédié à la gestion des inventaires, joue un rôle essentiel dans la configuration et la gestion des hôtes au sein de systèmes informatiques. Les inventaires constituent des ensembles logiques permettant d'organiser et de regrouper des hôtes, tels que des serveurs, des appareils réseau ou d'autres dispositifs informatiques, facilitant ainsi leur gestion et leur manipulation.

Au sein de cette section, plusieurs fonctionnalités clés sont disponibles pour simplifier la gestion des hôtes. Tout d'abord, l'ajout d'hôtes individuels permet d'intégrer de nouveaux dispositifs au sein de l'inventaire. Cela peut se faire manuellement en spécifiant les détails de chaque hôte, comme les adresses IP, les noms d'hôtes, les informations d'authentification et autres détails pertinents. Alternativement, il est souvent possible d'importer des listes d'hôtes à partir de fichiers ou d'autres sources externes pour une intégration plus rapide et efficace.

De plus, la fonction de modification offre la possibilité de mettre à jour et d'ajuster les détails des hôtes déjà présents dans l'inventaire. Cela inclut la modification des informations d'identification, la mise à jour des adresses IP ou des paramètres de connexion, ainsi que la gestion des groupes d'hôtes pour une organisation plus cohérente.

L'un des aspects les plus puissants de la gestion des inventaires réside dans la capacité à définir des variables spécifiques pour chaque hôte ou groupe d'hôtes. Ces variables permettent de personnaliser et d'adapter les configurations en fonction des besoins uniques de chaque dispositif. Par exemple, des variables peuvent être définies pour des paramètres de configuration spécifiques à un serveur, comme des variables d'environnement, des réglages de performance ou des détails de sécurité particuliers.

Par ailleurs, les inventaires peuvent être utilisés pour organiser les hôtes en fonction de différents critères, tels que les environnements (production, développement, test), les emplacements géographiques, les types de services offerts ou d'autres catégories pertinentes pour une infrastructure donnée. Cette classification facilite la gestion et l'exécution de tâches sur des ensembles spécifiques d'hôtes, permettant ainsi une automatisation efficace des processus.

En résumé, l'onglet inventaires dans AWX fournit une interface centrale et puissante pour la gestion des hôtes, offrant des fonctionnalités de création, de modification, de gestion de variables et d'organisation des hôtes au sein de groupes logiques. Cette fonctionnalité est essentielle pour les administrateurs système, les ingénieurs DevOps et les équipes d'automatisation des opérations, leur permettant de gérer facilement et efficacement des infrastructures informatiques complexes.

Capture d’écran 2024-01-29 091515

Organisation :
L'onglet Organisation dans AWX constitue une composante essentielle pour la gestion complète des utilisateurs, des rôles et des équipes au sein de cette plateforme d'automatisation des tâches. Cet espace offre un cadre structuré permettant aux administrateurs de définir et de contrôler les privilèges d'accès aux ressources et fonctionnalités d'AWX, tout en favorisant une collaboration fluide et sécurisée au sein des équipes travaillant sur des projets d'automatisation.

Dans l'onglet Organisation, les administrateurs ont la possibilité de créer, gérer et supprimer des comptes utilisateurs. Cette fonctionnalité est cruciale pour contrôler qui a accès à la plateforme, gérer les autorisations et garantir que seules les personnes autorisées puissent utiliser les fonctionnalités spécifiques d'AWX. Les informations personnelles des utilisateurs, telles que leurs noms, adresses e-mail et rôles attribués, peuvent être facilement ajustées et mises à jour depuis cet onglet.

En attribuant des rôles aux utilisateurs, les administrateurs définissent les permissions et les actions que chaque individu peut effectuer au sein de l'environnement AWX. Ces rôles peuvent être configurés de manière granulaire, permettant aux administrateurs de déterminer précisément quelles actions et quelles parties de l'infrastructure peuvent être manipulées par chaque utilisateur ou groupe d'utilisateurs. Par exemple, les rôles peuvent être définis pour autoriser ou restreindre l'accès à des inventaires, des modèles de jobs, des workflows, etc.

L'organisation des utilisateurs en équipes constitue une autre fonctionnalité clé de cet onglet. Les équipes permettent de regrouper des membres partageant des objectifs communs ou travaillant sur des projets spécifiques. Cette approche simplifie la gestion des autorisations en permettant aux administrateurs d'attribuer des autorisations et des rôles à une équipe entière plutôt qu'à chaque utilisateur individuellement. Ainsi, lorsqu'un utilisateur rejoint ou quitte une équipe, ses autorisations sont ajustées en conséquence, simplifiant la maintenance et la gestion des accès.

De plus, cette fonctionnalité favorise la collaboration en permettant aux membres de l'équipe de partager et de collaborer efficacement sur des projets communs. Les équipes peuvent avoir des responsabilités distinctes, des accès spécifiques et des interactions dédiées avec certains composants d'AWX, créant ainsi un environnement de travail collaboratif et structuré.

En résumé, l'onglet Organisation d'AWX est un élément central pour la gestion des utilisateurs, des rôles et des équipes au sein de la plateforme. Il offre un contrôle granulaire sur les autorisations, facilite la gestion des comptes utilisateurs et favorise la collaboration au sein des équipes travaillant sur des projets d'automatisation.

Capture d’écran 2024-01-29 091548

Notifications :
L'onglet Notifications dans AWX est une fonctionnalité cruciale pour la gestion des alertes et des notifications liées aux événements survenant dans l'environnement d'automatisation des tâches. Cette section offre une plateforme centrale pour configurer, personnaliser et gérer les notifications associées aux différents événements, permettant ainsi aux administrateurs de rester informés en temps réel de l'état des jobs, des erreurs, des succès ou des échecs dans leurs workflows d'automatisation.

L'une des fonctionnalités clés de la section Notifications est la capacité à définir des alertes pour des événements spécifiques. Cela inclut la fin d'un job, qu'il soit achevé avec succès ou qu'il ait échoué, ainsi que la détection d'erreurs critiques ou d'avertissements. Cette granularité permet aux équipes opérationnelles de recevoir des notifications ciblées, optimisant ainsi leur réactivité face aux problèmes potentiels.

AWX offre généralement plusieurs canaux de notification, notamment par e-mail, SMS, intégration avec des services de messagerie instantanée comme Slack ou Microsoft Teams, et même des systèmes de gestion des incidents comme PagerDuty ou ServiceNow. Cette flexibilité permet aux administrateurs de choisir le canal le plus approprié en fonction de la criticité de l'événement et des préférences de l'équipe.

La personnalisation des notifications est un aspect crucial de cette fonctionnalité. Les administrateurs peuvent définir des règles spécifiques pour chaque type d'événement. Par exemple, ils peuvent déterminer les destinataires des notifications en fonction des équipes responsables ou des niveaux de priorité des tâches, ce qui garantit que seules les personnes pertinentes reçoivent des alertes.

En outre, la gestion des horaires de notification est également prise en charge. Les administrateurs peuvent configurer des fenêtres horaires spécifiques pour envoyer des notifications, évitant ainsi les alertes inutiles en dehors des heures de travail ou planifiant des notifications différenciées pour les heures de pointe et les heures creuses.

L'onglet Notifications d'AWX joue un rôle essentiel dans l'amélioration de la visibilité opérationnelle et de la réactivité face aux événements critiques. En permettant une configuration fine des notifications et en offrant une gamme de canaux de communication, cette fonctionnalité contribue à l'efficacité opérationnelle en réduisant les temps d'arrêt, en accélérant la résolution des problèmes et en améliorant la collaboration au sein des équipes.

En résumé, cette section constitue un pilier central de la plateforme AWX, offrant aux administrateurs la capacité de personnaliser et de gérer les notifications d'événements critiques, ce qui contribue grandement à maintenir un environnement opérationnel fiable et réactif.
Configuration de la plateforme
Bienvenue dans la partie mère du cours après un loin périple d'apprentissage de plusieurs techno. C'est ici que vous allez apprendre la nécessité de ce genre de plateforme d'automatisation puis surtout vous aurez plus des pavés de 5000 pages, ce cours est quasi que de la manipulation, SUPER... Aller on y va sourire

Configuration Playbook
Dans un premier temps, vous avez besoin d'initialisé votre repository GitHub afin que la plateforme puisse voir vos fichier Ansible : Inventaire, Playbook, Vault

Pour cela il faut vous rendre sur l'onglet projet et cliquer sur la petite flèche verte en haut à droite afin de créer un nouveau projet et vous tomberez sur cette page :

Rentrer les informations comme sur le screenshoot, je vais vous expliquez :

Capture d’écran 2024-01-29 101947

Nom : Un nom pour votre projet est nécessaire, je vous conseil de donner un nom parlant
Laisser votre organisation par default, nous verrons les organisations plus tard
Type SCM : Git, très important car AWX va comprendre que vos fichier sont stocker dans un repository
URL du SCM : Le lien HTTPS de votre repo git, AWX va pouvoir cloner sur la plateforme
Branch SCM : main, AWX comprend que les fichiers sont dans cette branche et pas une autre (Vous avez pas besoin d'avoir plusieurs branche pour ce cours)
Cliquer sur enregistrer et vous avez officiellement un projet sur AWX !

On va maintenant ajouter les serveurs de l'infrastructure sur la plateforme en ajoutant un inventaire ! Pour cela, il faut aller dans l'onglet inventaire puis créer un nouveau inventaire :

Capture d’écran 2024-02-06 095625

Un nom pour l'inventaire
Laisser l'organisation par défaut
Il faut ensuite ajouter des sources à l'inventaire, cliquer sur votre inventaire franchement créer puis cliquer sur "Source" :

Créer une nouvelle source en cliquant sur le bouton + vert et renseigner les informations suivante :

Capture d’écran 2024-02-06 095726

Nom : Ajouter un nom à la source
Source : Provenance d'un projet, AWX va reconnaitre le fichier ou sera stocké les serveurs.
Projet : Sélectionner votre projet fraichement créer
Fichier d'inventaire : Sélectionner le fichier inventory.ini situer dans votre repository GitHub
Cliquer sur enregistrer, votre inventaire est créer !

On va ensuite configurer les credentials pour la sécurité des playbook.

Aller dans l'onglet "Information d'information" et créer une nouvelle credentiel en cliquant sur le petit + vert. Nous allons initié le mot de passe Vault afin que le playbook reconnaisse le mot de passe encrypté.

Renseigner les informations suivantes :

Capture2

Nom : Un nom à la credentiel qui parle
Organisation : Garder l'organisation par default
Type d'information d'identification : Chercher le mot clé "Coffre-fort" pour le Vault (Oui en français c'est magnifique)
Mot de passe de l'archivage sécurisé : Renseigner votre mot de passe que vous avez créer pour le Vault
Cliquer sur enregistrer et vous avez votre première credentiel mais c'est pas fini ! Vous n'utiliser pas le compte root de la machine, pour lancer vos playbooks, nous allons avoir besoin du mot de passe sudo. Pour initié ce mot de passe sur la plateforme, créer une credentiel puis renseigner les informations suivantes :

Capture3

Nom : Ajouter un nom qui parle
Organisation : Garder l'organisation par default
Type d'information d'identification : Chercher le mot clé "Machine" pour dire à AWX que c'est une credentiel de type server.
Méthode d'escalade privilégiée : sudo, comme la commande !
Mot de passe pour l'élévation des privilège : Ajouter le mot de passe sudo comme vous le connaissez : toor
Cliquer sur enregistrer et vous avez vos deux credentiels prêtes pour AWX

On va pouvoir lancer notre premier playbook depuis la plateforme ! On va tout simplement lancer notre playbook qu'on a développer dans le module Ansible.

Pour lancer notre premier modèle sur la plateforme, il faut cliquer sur l'onglet "modèle" puis sur le bouton + vert

Renseigner les informations :

Capture4

Nom : Ajouter à votre playbook
Inventaire : Sélectionner votre inventaire créer précédemment
Projet : Sélectionner votre projet créer précédemment
Type de job : Exécuter, c'est un playbook qu'on doit lancer
Playbook : Sélectionner le nom du fichier dans répository Github
Information d'identification : Rechercher et ajouter vos deux credentiel qui vous avez créer : Vault + Machine
Verbosité : 0
Activer l'élévation des privilèges : Cocher cette case, c'est pour activer le mode sudo
Cliquer sur enregistrer et votre playbook est créer, on peut maintenant s'amuser à le lancer ! Une fois créer vous pouver le launcher depuis la plateforme en cliquant sur la petite fusée :

Capture5

Normalement, si vous avez bien renseigner les bonnes informations. Vous avez pu vous connecter sur la machine, mais le playbook de fonctionnera pas car vous avez déjà les paquets :D

Gestion de la plateforme
Dans cette partie nous allons voir la partie gestion d'organisation, team d'utilisateur de la plateforme. Généralement dans une entreprise, les utilisateurs utilisent leurs identifiants de l'active directory lorsqu'ils souhaitent ce connecter sur la plateforme, cela évite de recréer des utilisateurs et d'avoir deux gestionnaires d'utilisateurs dans deux endroits.

Dans un premier temps on va créer une organisation Création d'une organisation

Modifié le: mardi 13 février 2024, 15:04

Malheureusement les bonnes choses ont une fin, ce chapitre signe la dernière ligne droite de ce cours.

Ce chapitre, loin d'être un simple adieu, est une invitation à poursuivre votre exploration de ce sujet, mais aussi de l'univers DevOps en continuel expansion !

Notre parcours jusqu'ici a été conçu comme une initiation, une découverte dans ce monde vaste des outils utilisés. Nous avons exploré les fondamentaux, compris les principes de base, et appliqué des concepts clés. Le monde de l'automatisation IT, de la conteneurisation, et de la gestion de configuration recèle de mode et technique d'utilisation plus complexes que nous n'avons fait que découvrir lors de ce cours.

Dans cette dernière section, nous vous ouvrons les portes de ce qui va au-delà du contenu de ce cours. Nous vous présenterons des techniques plus poussées, des outils alternatifs comme Podman face à avec Docker, ou encore Ansible Tower face à AWX et d'autres encore... Nous vous présenterons à travers ce dernier chapitre des intégrations plus techniques, et des stratégies d'optimisation qui vous permettrons d'améliorer votre compréhension et compétence dans l'utilisation de ces technologies DevOps.

Concrètement, compilé à notre cours, ce dernier chapitre vous permettra de voir, et des modes de fonctionnement plus technique de ce que vous avez appris, ainsi que des technologies se rapprochant de celle du cours, de façon a en savoir davantage sur ce sujet.

Pour la partie "Cas d'utilisation avancés d'Ansible et d'AWX", voici un développement détaillé :

Utilisation avancés d'Ansible et d'AWX

Nous explorons des scénarios d'automatisation plus technique que vu précédemment qui démontrent la polyvalence d'Ansible et d'AWX couplé. Ces cas d'utilisation sont assez pertinents et très utiliser pour les organisations cherchant à optimiser leur gestion d'automatisation système, elles sont très fréquemment utiliser dans les grandes sociétés comme Antoine a pu le dire, mais aussi utiliser chez des SSII pour leurs clients.

Gestion de configurations à grande échelle :
Contexte : Dans les grandes entreprises comme Sanofi par exemple, la gestion de configurations pour des centaines, voire des milliers de serveurs et d'applications, Ansible est là pour standardiser et automatiser la configuration de l'ensemble de l'infrastructure (playbooks, roles, block & jobs. AWX offre à cela une interface graphique pour gérer et suivre efficacement ces automatisations de manière centralisée et industriel. Nous avons fais des exercices sur une machines Linux et une machines WIndows, mais la force d'Ansible réside dans son déploiement de masse, de ce fait, il est possible de géré des grands inventaires de plusieurs milliers de machines...
Bénéfices : Réduction des erreurs humaines, cohérence des configurations à travers l'entreprise (déploiement de masse standardisé), et évidemment un gain de temps considérable.


Intégration avec des systèmes cloud :
Contexte : Les environnements cloud, comme AWS, Azure, ou GCP, ont des besoins spécifiques en termes de gestion et d'automatisation, Évidemment, AWX permet un lien entre votre potentiel partie On-Premise et Cloud Provider.
Concrètement... : Créez des Jobs Ansible pour gérer automatiquement les ressources cloud (comme les instances VM, les réseaux, le stockage) et intégrez-les dans AWX pour une gestion centralisée, il est par exemple possible de créer des inventaires dynamique, de ce fait, en créant par exemple des machines sur AWS, avec un TAG spécifique, AWX, en étant paramétrer correctement, aura la possibilité de repérer ces tags et ainsi les rendre disponibles sur AWX afin d'y lancer des Jobs.
Bénéfices : Une efficacité dans la gestion des ressources cloud (VM, S3...) et une intégration fluide et dynamique avec l'infrastructure existante.


Faisons maintenant une comparaison entre AWX et Ansible Tower... une alternative ???

nous examinerons ici les différences entre AWX et Ansible Tower, en discutant de leurs avantages et de leurs inconvénients. Cette comparaison vous permettra de mieux comprendre quand opter pour l'un ou l'autre outil. Sachez pour en tout cas, qu'il s'agit de 2 produits RedHat et ceux-ci restent assez similaire et fond par principe la même chose, de la gestion de configuration.

AWX :

Fonctionnalités : AWX est la version open-source d'Ansible Tower. Il offre la plupart des fonctionnalités de Tower, comme l'interface graphque, les workflows, la gestion des inventaires dynamique, la synchronisation LDAP/Github/Cloud Provider... et le contrôle d'accès basé sur les rôles.
Avantages : Gratuit et open-source, AWX est idéal pour l'expérimentation notamment pour des labs, le développement de compétences, et les environnements non critiques tel que les environnements de développement ou bien de pré-production. L'open-source favorise une personnalisation et une adaptation plus souples du produit.
Inconvénients : Comme il s'agit d'un produit open-source, il ne bénéficie pas du support officiel, ce qui est un frein considérable pour les environnements de production, aussi, certaines fonctionnalités avancées d'Ansible Tower ne sont pas disponibles sur AWX, il n'est donc pas possible d'aller aussi loin dans la technicité des infrastructures. Sa stabilité et sa fiabilité peuvent être moindres en comparaison (moins de mise à jours, corrections, mais possède une large communauté sur Github/StackOverfkow.
Ansible Tower :

Fonctionnalités : Ansible Tower est la version entreprise d'AWX proposé par RedHat. Il offre toutes les fonctionnalités d'AWX, plus des fonctionnalités avancées comme le support multi-tenant, des intégrations d'entreprise réaliser par les équipes redhat, des fonctionnalités de reporting avancées, et évidemment, un support d'entreprise.
Avantages : Avec le support d'Ansible ainsi qu'une plus grande stabilité, Tower est mieux adapté aux environnements de production. Les fonctionnalités supplémentaires facilitent la gestion à grande échelle et offrent une meilleure intégration avec d'autres outils d'entreprise, permettant de pousser la technicité des infrastructures au maximum.
Inconvénients : Ansible Tower est un produit évidemment payant, ce qui peut être un obstacle pour les petites entreprisesou bien même les admin sys souhaitant monter en compétence sur ce système. Sa nature moins ouverte peut limiter la personnalisation, il n'est pas Open-Source, vous ne faites pas ce que vous souhaiter !


Mais alors... j'utilise lequel et dans quelle circonstance ?????

AWX

Les environnements de test et de développement.
Expérimentation d'Ansible avec gestion de configuration et interface Graphique sans coût initial.
Les projets où la personnalisation open-source est essentielle.
Ansible Tower

Les environnements de production.
Les organisations nécessitant un support officiel et une garantie de stabilité avec des mises à jours de sécurités perpétuels.
Les cas d'utilisation nécessitant des fonctionnalités avancées et une intégration poussée.
Voilà, maintenant vous savez quoi prendre !

Parlons Intégration...

Nous discuterons ici de l'intégration d'AWX et d'Ansible avec d'autres outils DevOps, ils en existe énormément dans cet univers,Jenkins, GitLab CI/CD, et bien d'autres... Ces derniers permettent par exemple créer des pipelines d'automatisation plus robustes et efficaces. L'intégration de ces outils joue un rôle réellement crucial dans l'orchestration des processus DevOps (push2prod), améliorant ainsi la cohérence, la vitesse et l'efficacité des opérations IT. Ils sont très utiliser dans les grandes entreprises mais nécessite une bonne compréhension de l'environnement, des bonnes pratiques et des outils afin de mettre en place ces derniers.



Jenkins :

Comment ça marche ? Jenkins ( Logiciel Open-Source permettant automatiser les parties du développement logiciel) peut déclencher des jobs Ansible pour automatiser les tâches de déploiement, de test, et de gestion de configuration liées au build dans le cadre d'un pipeline CI/CD.
Quoi d'plus ? Cette intégration permet de combiner la puissance d'Ansible dans l'automatisation des configurations combiné à la flexibilité de Jenkins dans la gestion des pipelines CI/CD, cela offre un contrôle totale et une automatisation plus fine des processus de déploiement.
Intégration avec GitLab CI/CD :

Comment ça marche ? Concernant les pipelines CI/CD de GitLab (version OpenSource & local de GitHub), Ansible peut être utilisé pour exécuter des tâches d'automatisation lors de différents stades du pipeline (comme le déploiement, la mise à jour de configurations, etc.).
Avantages L'intégration d'Ansible avec GitLab CI/CD permet une gestion possiblement autonome des déploiements et des mises à jour, facilitant ainsi la livraison continue et la gestion de l'infrastructure as code, nous avons pu le voir dans les précédents exercices sourire
Il en existe beaucoup d'autres...

Autres outils : AWX/Ansible peut également s'intégrer avec d'autres outils DevOps comme Terraform, Kubernetes, des systèmes de monitoring comme Prometheus... Ceux-ci, couplé à AWX/Ansible permettent, dans le cas où ceux-ci sont très bien maîtrisé, de maintenir un environnement de production très stable et très sécuritaire, en plus d'une possibilité d'évolution et de mise en production d'outil tierce très rapide, de façon plus claire, en maitrisant ces outils, vous pouvez faire en sorte d'avoir un énorme gain de productivité...
---
Alternatives à Docker ? OUI !!!

Dans ce monde en constante évolution de l'IT, Docker a longtemps été le standard de facto concernant la conteneurisation. Cependant, d'autres technologies ont émergé, offrant des alternatives intéressantes. Parmi elles, Podman se démarque particulièrement. Nous allons donc la comparé avec Docker, et vous en dire plus...



Podman :
ça sert à quoi ?? : Podman est souvent considéré comme un remplacement direct de Docker, il est en 2ème position des technologie de conteneurisation les plus en vogue. Il permet de construire, de gérer et de lancer des conteneurs sans nécessiter de daemon en arrière-plan. Podman est compatible avec les images Docker et peut souvent les exécuter sans aucune modification, Concrètement, vous n'aurez aucun mal à passer de Docker à Podman en terme d'utilisation, il vous suffit de remplacer le mot "Docker" par "podman" à chaque commande ahah! Comme dit précédemment, la seul différence est son fonctionnement (sans nécessiter de daemon).
Sécurityyyy : L'une des principales différences de Podman par rapport à Docker c'est son modèle de sécurité en effet Podman exécute chaque conteneur en tant qu'utilisateur non privilégié, réduisant ainsi les risques de sécurité liés au daemon Docker(moins de risque de sécurité), de ce fait, ce dernier va être au niveau machine, beaucoup plus sécuriser et permettrat de mieux segmenter ces derniers !
Usage : Podman est particulièrement adapté dans les environnements où la sécurité est une préoccupation (comme dans toutes entreprises je l'espère), ou pour les utilisateurs qui préfèrent une architecture sans daemon, sur le côté usage de production, le fonctionnement reste le même que partout, c'est un systeème de container.
Piqure de rappel sur Docker... : - Docker : - Fonctionnalités : Docker est reconnu pour sa facilité d'utilisation, son écosystème étendu, et sa large adoption permettant d'être reconnu par une large communeauté d'utilisateurs).

Sécurité : Docker fonctionne avec un daemon central, ce qui peut présenter des risques de sécurité si le daemon est compromis, même si ce dernier s'améliore après chaque patch de sécurité.

Usage : Docker est un choix privilégié pour les développeurs et les équipes DevOps/SysOps en raison de sa communauté vaste et de son écosystème riche, offrant une grande variété d'outils et de services intégrés, en plus de ça, étant le numéro 1, il est le premier vers lequel on se tourne pour découvrir la conteneurisation.

Pour conclure, bien que Docker reste un choix populaire dans l'écosystème de la conteneurisation, des alternatives comme Podman offrent des avantages distincts en termes de sécurité et de fonctionnalités. Le choix entre Docker et podMan (même si il en existe plein d'autres tel que Swarm, rkt, LXC...) dépendra largement des besoins spécifiques de sécurité, de l'architecture du système, et des préférences personnelles ou organisationnelles. Bien que Docker soit le numéro 1, ce dernier n'a plus le vent en poupe depuis quelques année, et pour cause, beaucoup se plaignent de certains soucis (sécurité lié au daemon, grossissement des images, difficulté en debugging...).



---
Ressources complémentaire....

Ce cours touche à sa fin.... Pour ceux qui cherchent à approfondir leurs connaissances en automatisation IT, en conteneurisation et même dans l'utilisation d'outils DevOps tels que Ansible, AWX, et Docker, il existe une multitude de ressources disponibles à votre porté. Nous vous proposons une liste de cours en ligne, forums, et groupes de discussion qui peuvent enrichir votre apprentissage sur le sujet et vous garder à jour avec les dernières tendances et meilleures pratiques, car oui, dans notre domaine, la veille c'est important !!

Cours en ligne :

Coursera et Udemy : Ces plateformes offrent énormément de cours couvrant Ansible, Docker, et d'autres technologies DevOps, adaptés à tous les niveaux de compétence, il vous suffira te rechercher votre sujet, et de trouver le cours qui vous correspond !
Linux Academy : Spécialisée dans les technologies open-source, Linux Academy propose des cours détaillés sur Ansible, Docker et d'autres technologies de cette univers ! (n'oubliez pas que le meilleur cours sur ce sujet c'est le notre !)
Forums et Communautés :

Stack Overflow : Un incontournable pour toute question technique, avec une communauté active et des discussions approfondies sur Ansible, Docker, et bien plus. Mais vous devez connaître la chanson !
Reddit : Les sous-forums tels que r/devops, r/ansible et r/docker sont d'excellentes sources pour des conseils, des actualités et des discussions avec d'autres professionnels. (Pour l'anecdote, c'est sur Reddit que j'ai appris le forks de Terraform en fin 2023 !).
Github: Entre les repos public, les issues & les wikis, combinés à une très large communauté, vous trouverez sur Github beaucoup d'information de TP, de "pseudo-cours", et même des choses toutes faites qui pourrons vous servir tel que des playbook disponible en libre service !
- Ansible Galaxy : Vous vous en souvenez, Ansible Galaxy est un site proposé par et soutenu par Redhat afin de rendre publique et disponible des travaux & projet sur Ansible, vous y trouverez des pugins, rôles et playbook ansible proposé par la communeauté ! - DockerHub : Comme pour Ansible Galaxy, DockerHub est un site/plateforme permettant de déposer, ou bien récupéré du contenu (DockerFile, image de container...) proposé par la communauté, veillez tout de même a bien vérifier ce que vous télécharger, le risque 0 n'existe pas quand il s'agit de contenu communautaire.

Sans-titre

Groupes de discussion :
Ansible et Docker Meetups : Rejoignez des meetups locaux ou en ligne pour rencontrer d'autres professionnels et partager des connaissances et des expériences.
Groupes LinkedIn et Facebook : Ces plateformes que vous connaissez sans doutes proposent des groupes dédiés où les professionnels partagent des ressources, des conseils, et des opportunités de réseautage, parfait pour se faire de nouveaux collègues !
Ces ressources vous aideront non seulement à consolider vos connaissances actuelles, mais aussi à rester informé des évolutions dans le domaine de l'automatisation IT et du DevOps de manière général. La formation continue est un élément clé pour rester compétitif dans cde domaine en constante évolution.

Merci à tous !

Modifié le: vendredi 19 janvier 2024, 14:20
Récapitulatif des thèmes abordés
Récapitulatif des Cours Abordés
Au cours de ce parcours de formation, nous avons exploré de manière approfondie la plateforme AWX et les technologies qui l'entourent: la conteneurisation, Ansible, et GitHub. Chaque module a été conçu pour non seulement introduire les concepts fondamentaux mais aussi pour offrir une expérience pratique à travers des exercices et des projets.

Présentation de l'Équipe et Introduction au Sujet

-Nous vous avons présenter l'Introduction par Antoine et Rémi à la plateforme AWX et à l'utilité d'Ansible dans la pratique, ainsi qu'une vue d'ensemble du parcours de formation.

Mise en Place de l'Environnement

Création de l'infrastructure nécessaire via VirtualBox, incluant la VM node, le serveur AD, et la VM master avec les conteneurs AWX.
Tutoriels sur l'importation et la configuration des VMs sur VirtualBox.
Explications détaillées de l'environnement de travail, flux réseaux principalement !
Introduction à la Conteneurisation et YAML

Apprentissage des concepts de base de la conteneurisation et création du premier Dockerfile.
Introduction au YAML, avec focus sur la syntaxe clé/valeur > avec et sans liste.
Exercices pratiques sur Docker et YAML, suivis d'un QCM pour évaluer la compréhension de nos apprenants.
Correction et explications des QCMs via vidéo et récapitulatif vidéo du module.
Introduction à Ansible et GitHub

Définition et utilisation d'Ansible pour l'automatisation, nous avons découvert ce superbe produit et réalisé nos premier faits d'armes dessus.
Création de playbooks et de rôles avec Ansible, et oui, il faut pratiquer pour que ça rentre !!
Introduction à GitHub, création de repos et ajout de clés SSH, nous vous avons présenter un large tutoriel de ce que nous pouvons retrouver sur github, afin de pouvoir pleinement l'utiliser.
Exercices pratiques sur Ansible et GitHub, évaluation par QCM, et correction vidéo des exercices Ansible.
Déploiement d’AWX

Méthodologie pour déployer AWX à l'aide de conteneurs Docker, comment ça marche...
Exploration du contenu des conteneurs AWX pour les utilisateurs curieux, nous vous avons présenter dans ce sous-chapitres ce que contenait nos dockerfiles et comment ces derniers fonctionnaient entres eux.
Introduction et Pratique d’AWX

Découverte et pratique des différentes fonctionnalités d'AWX, découverte des différents onglets, et mise en place de petit paramétrage afin de comprndre comment nous interagissons avec ce produit, inventaires, jobs, authentification... la totale !
Tutoriel vidéo sur l'authentification LDAP, étant donné qu'il s'agit d'une partie importante qui ne concerne pas réellement du Ansible pur et dure, une vidéo était ici la bienvenue, cela permet de ne pas rester bloqué sur cette partie !
TP Final

Il s'agissait d'un TP reprenant toutes les compétences normalement acquises lors du cours, vous avez pu ici, pratiquer du windows, du linux, du powershell, du Ansible en utilisant donc du YAML, de l'utilisation de Github, et évidemment, du AWX via sa superbe interface Graphique !

Ajouter sur AWX l'hôte ADDS en hôte Windows (Inventaire sur Github).
Créer un Playbook permettant de créer un compte ActiveDirectory sur notre serveur Windows et d'ajouter ce compte au groupe "Awx_Required_Group" (permettant l'accès à AWX).
Mettre ce playbook dans GitHub et l'exécuter dans AWX.
Se connecter avec ce nouveau compte sur AWX.
Configurer son nouveau compte sur AWX (synchronisation Github, Inventaire, Vault).
Ajouter sur AWX l'hôte VM_NODE en hôte Linux (Inventaire sur Github).
Créer un second playbook permettant d'installer 3 paquets différents (au choix) sur le VM_NODE.
Mettre ce playbook dans GitHub et le mettre à disposition d'AWX avec la synchronisation (sans l'exécuter).
Planifier ce playbook sur AWX via le lancement différé, puis attendre l'exécution du playbook.
Se reconnecter en tant qu'Administrateur sur AWX.
Monitoring: grâce à l'interface Graphique, vérifier que le playbook précédent a bien été exécuté et a bien fonctionné.
Pour Aller Plus Loin

Introduction aux concepts avancés de CI/CD et exploration d'autres plateformes professionnelles similaires à AWX...
Récapitulatif Général et Bibliographie

Consolidation des connaissances et compétences acquises tout au long du cours.
Correction des exercices et TP, accompagnée d'une bibliographie pour retrouver nos sources, et bien d'autres pour que vous puissiez avancer de votre côté sur ce sujet.
Modifié le: mercredi 7 février 2024, 09:36

Correction et explication Container
Correction et Explication des Exercices
Correction de l'Exercice 1
Commande à exécuter: bash docker ps
Explication:
docker ps: Cette commande affiche les conteneurs actuellement en cours d'exécution. Pour voir tous les conteneurs, y compris ceux qui sont arrêtés, vous pouvez utiliser docker ps -a.
Correction de l'Exercice 2
Commande à exécuter: bash docker run -it ubuntu
Explication:
docker run -it ubuntu: Cela démarre un nouveau conteneur basé sur l'image Ubuntu avec un terminal interactif. Une fois à l'intérieur, vous pouvez exécuter diverses commandes comme ls et pwd. Pour quitter le conteneur, tapez simplement exit.
Correction de l'Exercice 3
Commande à exécuter: bash docker run -d -p 80:80 --name mon_apache httpd Puis, pour exécuter la commande ls: bash docker exec mon_apache ls Pour ouvrir un shell interactif: bash docker exec -it mon_apache /bin/bash
Explication:
La première commande exécute un conteneur Apache en arrière-plan et mape le port 80 du conteneur au port 80 de la machine hôte.
docker exec: Permet d'exécuter une commande à l'intérieur d'un conteneur en cours d'exécution.
Correction de l'Exercice 4
Commande à exécuter: bash docker run -e MYSQL_ROOT_PASSWORD=password -d mysql Pour vérifier l'état: bash docker ps Pour arrêter et supprimer le conteneur: bash docker stop <ID_du_conteneur> docker rm <ID_du_conteneur>
Explication:
Cette commande démarre un conteneur MySQL en arrière-plan avec un mot de passe défini pour l'utilisateur root.
Correction de l'Exercice 5
L'objectif de cet exercice est de comprendre comment lier des volumes avec Docker.

Création d'un répertoire sur le système hôte:

mkdir /mon/repertoire
Exécution du conteneur MySQL en liant le répertoire:

docker run -e MYSQL_ROOT_PASSWORD=password -d -v /mon/repertoire:/var/lib/mysql mysql
Vérification des données MySQL: Vous pouvez vérifier que les données MySQL sont stockées dans le répertoire /mon/repertoire sur votre système hôte.

Arrêt et suppression du conteneur:

docker stop <ID_du_conteneur>
docker rm <ID_du_conteneur>
Recréation du conteneur avec le même répertoire lié:

docker run -e MYSQL_ROOT_PASSWORD=password -d -v /mon/repertoire:/var/lib/mysql mysql
Vérification des données après la recréation du conteneur: Vérifiez que les données sont toujours présentes dans le répertoire /mon/repertoire même après avoir supprimé et recréé le conteneur.

Correction et explication YML
Correction - Exercice 1
Tâche : La tâche consistait à écrire un fichier YAML pour décrire un animal en utilisant une indentation appropriée pour chaque niveau d'information.

Exemple pour le Lion :

animal:
  type: Mammifère
  caractéristiques:
    - Grande crinière
    - Carnivore
    - Forte et puissante
  habitat:
    - Savane
    - Régions grasses d'Afrique
Explication : - Chaque niveau d'information est indenté par deux espaces supplémentaires par rapport au niveau précédent. - Le nom de l'animal, "lion", est au premier niveau d'indentation. - Les informations comme le type, les caractéristiques et l'habitat sont des clés (key) associées à leurs valeurs (value). - Le système de clé-valeur permet de structurer les données de manière lisible et organisée. - Les valeurs peuvent être de différents types : chaînes de caractères, listes, nombres, etc. - Par exemple, sous la clé "caractéristiques", nous avons une liste (indiquée par le tiret "-") de caractéristiques du lion. Cela permet de représenter plusieurs valeurs pour une même clé.

Correction - Exercice 2
Tâche : La tâche consistait à créer un fichier YAML pour une liste de courses avec différentes catégories, en utilisant l'indentation de manière appropriée.

Exemple concret d'une liste de courses :

courses:
  légumes:
    - carottes
    - épinards
    - tomates
  fruits:
    - pommes
    - bananes
    - oranges
  produits_laitiers:
    - lait
    - yaourt
  viandes:
    - poulet
    - bœuf
Explication : - Chaque catégorie est indentée par deux espaces de plus que la catégorie parente. - Les éléments de chaque catégorie sont indentés de deux espaces par rapport à leur catégorie parente.

Correction - Exercice 3
Tâche : La tâche consistait à écrire un fichier YAML pour une recette de pizza en expérimentant avec différentes indentations.

Exemple d'une recette de Pizza :

recette:
  nom: Pizza Margherita
  ingrédients:
    - Pâte à pizza
    - Sauce tomate
    - Mozzarella
    - Basilic frais
    - Huile d'olive
  étapes:
    - Préchauffer le four à 220°C.
    - Abaisser la pâte à pizza sur une plaque.
    - Étaler la sauce tomate sur la pâte.
    - Répartir la mozzarella et les feuilles de basilic.
    - Arroser d'un filet d'huile d'olive.
    - Enfourner pendant 12-15 minutes, jusqu'à ce que la croûte soit dorée.
Explication : - L'indentation est utilisée pour structurer les différentes parties de la recette (nom, ingrédients, étapes) de manière claire. - Chaque niveau d'information est indenté de deux espaces supplémentaires par rapport au niveau précédent, créant une hiérarchie visuelle.

Modifié le: mercredi 18 octobre 2023, 16:33

Correction et Explication Ansible
Comme promis ! vous trouverez ici les corrections des 3 exercices Ansible.

Correction Exercice 1 - Utilisation des commandes ad-hoc
Tâche 1: Utiliser le module ping
Objectif : Vérifier la connectivité avec tous les hôtes définis dans votre inventaire.
Commande : bash ansible all -m ping
Explication :

all spécifie que la commande doit être exécutée sur tout les hôtes, en l'occurrence, notre unique machine vm_node .

-m ping permet d'utiliser le module ping. Il va donc pinguer notre autre, et renvoyer pong si les paquets sont passés !

Tâche 2: Module file pour créer un dossier
Objectif : Créer un dossier test_directory dans le répertoire /tmp sur notre hôte.
Commande : bash ansible all -m file -a "path=/tmp/test_directory state=directory"
Explication :

-m file indique d'utiliser le module file.

-a "path=/tmp/test_directory state=directory" sert pour les arguments à passer au module. Ici, path pour le chemin à créer, et state=directory indique le type de création, en l'occurrence un dossier.

Tâche 3: Module command pour vérifier l'espace disque
Objectif : Vérifier l'espace disque disponible sur notre hôte
Commande : bash ansible all -m command -a "df -h"
Explication :
-m command utilise le module command.
-a "df -h" envoie la commande df -h à notre hôte et affiche l'espace disque disponible.
---
Correction Exercice 2 - Création d'un Playbook Simple
Objectif :
Créer un playbook update_system.yml pour mettre à jour et installer certains paquets sur notre hôte

Playbook : update_system.yml
---
- name: MAJ Update OS
  hosts: vm_node   #(ou mettre son titre de groupe présent dans le fichier inventaire.ini)
  become: yes
  tasks:
    - name: MAJ paquet-list
      apt:
        update_cache: yes

    - name: MAJ Upgrade paquet
      apt:
        upgrade: dist

    - name: Installation de Python
      apt:
        name: python
        state: present

    - name: Installation de NGINX
      apt:
        name: nginx
        state: present
et oui... c'est aussi simple que ça, maintenant imaginez de faire sur 50 machines... Un gain de productivité considérable.

Explications :
become: yes permet d'exécuter des tâches avec des privilèges root (équivalent du sudo).

Tâche 1 - Maj liste des paquets :

Utilisation du module apt (utiliser DNF pour du redhat).

update_cache: yes commande à apt de rafraîchir sa liste de paquets présent.

Tâche 2 - Maj des paquets :

Toujours avec le module apt.

upgrade: dist commande à apt pour maj les paquets vers les dernières versions disponibles.

Tâche 3 - Installation de Python :

Utilise encore le module apt.

name: python spécifie le paquet à installer (ici, Python).

state: present assure que le paquet est installé. Si déjà installé, aucune action n'est prise, il skippera sans erreurs.

Tâche 4 - Installation de NGINX :

Similaire à la tâche d'installation de Python, mais pour NGINX.
Exécution du Playbook :
ansible-playbook -i inventaire.ini update_system.yml
-i inventaire.ini pour le fichier d'inventaire où est contenu notre vm_node

update_system.yml fichier de playbook que vous exécutez.

---
Correction - Exercice 3 - Création d'un Rôle Simple
Objectif :
Créer un rôle basic_setup qui effectue des tâches de configuration initiale sur le vm_node.

Création du Rôle :
Initialisation du Rôle : Utilisez la commande ansible-galaxy pour initialiser la structure du rôle (création du tree) :

ansible-galaxy init basic_setup
Cela va créer un nouveau répertoire basic_setup avec la structure de dossiers pour les rôles.

Structure du Rôle :

tasks: Tâches principales.
files: Fichiers à copier sur vm_node.
templates: Modèles Jinja2.
vars: Variables du rôle.
defaults: Valeurs par défaut des variables.
meta: Informations sur le rôle.
Contenu du Rôle :
tasks/main.yml:

- name: Installer vim
apt:
  name: vim
  state: present

- name: Créer un fichier de configuration
copy:
  src: settings.conf
  dest: /etc/myapp/settings.conf
files/settings.conf: Créez un fichier de configuration simple:

# settings.conf
antoine=sanofi
remi=grandlyon
Explications :
Tâche 1 - Installer vim :

Utilise le module apt pour installer vim.
state: present s'assure que vim est bien installé.
Tâche 2 - Créer un fichier de configuration :

Utilise le module copy pour copier le fichier settings.conf depuis le dossier files du rôle vers le chemin /etc/myapp/settings.conf sur notre hôte
Utilisation du Rôle dans le Playbook :
Créez un playbook : ```yaml
hosts: all become: yes roles:
basic_setup ```
Exécution du Playbook : Utilisez la commande suivante pour exécuter le playbook : bash ansible-playbook setup.yml
Modifié le: mardi 14 novembre 2023, 08:56












